{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ApssetD_Ob5"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import tarfile\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import xml.dom.minidom\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import regex as re\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.backend import expand_dims\n",
        "from tensorflow import concat\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "tf.keras.backend.clear_session()\n",
        "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM,Layer,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import repeat\n",
        "from sklearn.utils import shuffle\n",
        "import nltk.translate.bleu_score as bleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://drive.google.com/uc?id=1U7D9lnjH-0CaXzhmua2rMtmdgS4DEH2k'\n",
        "output = 'proccessed.pkl'\n",
        "gdown.download(url, output, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "obSzDx1I_dOe",
        "outputId": "fd787407-e262-4d07-fe33-74d9002e3b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1U7D9lnjH-0CaXzhmua2rMtmdgS4DEH2k\n",
            "To: /content/proccessed.pkl\n",
            "100%|██████████| 58.1M/58.1M [00:00<00:00, 82.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'proccessed.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle('/content/proccessed.pkl')\n"
      ],
      "metadata": {
        "id": "h9jRQouL_sDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "UfWgWNHK_6BI",
        "outputId": "c058adc1-d986-43a5-f243-01086aeaba23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  patient_id                                      image1  \\\n",
              "0    CXR3556  /content/png/CXR3556_IM-1741-1001-0001.png   \n",
              "2      CXR32         /content/png/CXR32_IM-1511-1001.png   \n",
              "4     CXR260        /content/png/CXR260_IM-1090-1001.png   \n",
              "5    CXR1301       /content/png/CXR1301_IM-0198-1001.png   \n",
              "6    CXR1921       /content/png/CXR1921_IM-0598-1001.png   \n",
              "\n",
              "                                       image2  \\\n",
              "0  /content/png/CXR3556_IM-1741-1001-0002.png   \n",
              "2         /content/png/CXR32_IM-1511-4001.png   \n",
              "4        /content/png/CXR260_IM-1090-2001.png   \n",
              "5       /content/png/CXR1301_IM-0198-2001.png   \n",
              "6       /content/png/CXR1921_IM-0598-2001.png   \n",
              "\n",
              "                                            findings  \\\n",
              "0  the lungs are clear. there is no pleural effus...   \n",
              "2  the heart is normal in size. the mediastinum i...   \n",
              "4  lungs are clear bilaterally. cardiac and media...   \n",
              "5  heart size within normal limits, stable medias...   \n",
              "6  redemonstration of moderately-inflated lungs, ...   \n",
              "\n",
              "                                      image_features  \\\n",
              "0  [[0.00041582860285416245, 0.001570420921780169...   \n",
              "2  [[0.0005354544264264405, 0.0019668142776936293...   \n",
              "4  [[0.0002745636156760156, 0.0018877924885600805...   \n",
              "5  [[0.0005874697235412896, 0.0018448150949552655...   \n",
              "6  [[0.00029747304506599903, 0.0014215346891433, ...   \n",
              "\n",
              "                                      findings_total  \\\n",
              "0  <start> the lungs are clear. there is no pleur...   \n",
              "2  <start> the heart is normal in size. the media...   \n",
              "4  <start> lungs are clear bilaterally. cardiac a...   \n",
              "5  <start> heart size within normal limits, stabl...   \n",
              "6  <start> redemonstration of moderately-inflated...   \n",
              "\n",
              "                                              dec_ip  \\\n",
              "0  <start> the lungs are clear. there is no pleur...   \n",
              "2  <start> the heart is normal in size. the media...   \n",
              "4  <start> lungs are clear bilaterally. cardiac a...   \n",
              "5  <start> heart size within normal limits, stabl...   \n",
              "6  <start> redemonstration of moderately-inflated...   \n",
              "\n",
              "                                              dec_op  \n",
              "0  the lungs are clear. there is no pleural effus...  \n",
              "2  the heart is normal in size. the mediastinum i...  \n",
              "4  lungs are clear bilaterally. cardiac and media...  \n",
              "5  heart size within normal limits, stable medias...  \n",
              "6  redemonstration of moderately-inflated lungs, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35209568-d0db-43c4-b065-5a8651c732d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>image1</th>\n",
              "      <th>image2</th>\n",
              "      <th>findings</th>\n",
              "      <th>image_features</th>\n",
              "      <th>findings_total</th>\n",
              "      <th>dec_ip</th>\n",
              "      <th>dec_op</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CXR3556</td>\n",
              "      <td>/content/png/CXR3556_IM-1741-1001-0001.png</td>\n",
              "      <td>/content/png/CXR3556_IM-1741-1001-0002.png</td>\n",
              "      <td>the lungs are clear. there is no pleural effus...</td>\n",
              "      <td>[[0.00041582860285416245, 0.001570420921780169...</td>\n",
              "      <td>&lt;start&gt; the lungs are clear. there is no pleur...</td>\n",
              "      <td>&lt;start&gt; the lungs are clear. there is no pleur...</td>\n",
              "      <td>the lungs are clear. there is no pleural effus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CXR32</td>\n",
              "      <td>/content/png/CXR32_IM-1511-1001.png</td>\n",
              "      <td>/content/png/CXR32_IM-1511-4001.png</td>\n",
              "      <td>the heart is normal in size. the mediastinum i...</td>\n",
              "      <td>[[0.0005354544264264405, 0.0019668142776936293...</td>\n",
              "      <td>&lt;start&gt; the heart is normal in size. the media...</td>\n",
              "      <td>&lt;start&gt; the heart is normal in size. the media...</td>\n",
              "      <td>the heart is normal in size. the mediastinum i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CXR260</td>\n",
              "      <td>/content/png/CXR260_IM-1090-1001.png</td>\n",
              "      <td>/content/png/CXR260_IM-1090-2001.png</td>\n",
              "      <td>lungs are clear bilaterally. cardiac and media...</td>\n",
              "      <td>[[0.0002745636156760156, 0.0018877924885600805...</td>\n",
              "      <td>&lt;start&gt; lungs are clear bilaterally. cardiac a...</td>\n",
              "      <td>&lt;start&gt; lungs are clear bilaterally. cardiac a...</td>\n",
              "      <td>lungs are clear bilaterally. cardiac and media...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CXR1301</td>\n",
              "      <td>/content/png/CXR1301_IM-0198-1001.png</td>\n",
              "      <td>/content/png/CXR1301_IM-0198-2001.png</td>\n",
              "      <td>heart size within normal limits, stable medias...</td>\n",
              "      <td>[[0.0005874697235412896, 0.0018448150949552655...</td>\n",
              "      <td>&lt;start&gt; heart size within normal limits, stabl...</td>\n",
              "      <td>&lt;start&gt; heart size within normal limits, stabl...</td>\n",
              "      <td>heart size within normal limits, stable medias...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CXR1921</td>\n",
              "      <td>/content/png/CXR1921_IM-0598-1001.png</td>\n",
              "      <td>/content/png/CXR1921_IM-0598-2001.png</td>\n",
              "      <td>redemonstration of moderately-inflated lungs, ...</td>\n",
              "      <td>[[0.00029747304506599903, 0.0014215346891433, ...</td>\n",
              "      <td>&lt;start&gt; redemonstration of moderately-inflated...</td>\n",
              "      <td>&lt;start&gt; redemonstration of moderately-inflated...</td>\n",
              "      <td>redemonstration of moderately-inflated lungs, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35209568-d0db-43c4-b065-5a8651c732d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35209568-d0db-43c4-b065-5a8651c732d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35209568-d0db-43c4-b065-5a8651c732d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e73f7918-c0f3-4cb7-b835-d64090667181\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e73f7918-c0f3-4cb7-b835-d64090667181')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e73f7918-c0f3-4cb7-b835-d64090667181 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3337,\n  \"fields\": [\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3337,\n        \"samples\": [\n          \"CXR1320\",\n          \"CXR3942\",\n          \"CXR2428\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3337,\n        \"samples\": [\n          \"/content/png/CXR1320_IM-0207-1001.png\",\n          \"/content/png/CXR3942_IM-2013-1001.png\",\n          \"/content/png/CXR2428_IM-0970-1001.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3337,\n        \"samples\": [\n          \"/content/png/CXR1320_IM-0207-2001.png\",\n          \"/content/png/CXR3942_IM-2013-2001.png\",\n          \"/content/png/CXR2428_IM-0970-3001.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"findings\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2548,\n        \"samples\": [\n          \"the heart is top normal in size. the mediastinum is stable. the aorta is atherosclerotic. there are mild chronic changes without focal consolidation. no pleural effusion is seen.\",\n          \"the lungs are clear. there is hyperinflation of the lungs. there is no pleural effusion or pneumothora. the heart and mediastinum are normal. mild arthritic changes of the spine are present.\",\n          \"the lungs are clear. there is no pleural effusion or pneumothora. the heart is not significantly enlarged. there are atherosclerotic changes of the aorta. there are severe arthritic changes of the with mild arthritic changes of the thoracic spine.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"findings_total\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2548,\n        \"samples\": [\n          \"<start> the heart is top normal in size. the mediastinum is stable. the aorta is atherosclerotic. there are mild chronic changes without focal consolidation. no pleural effusion is seen. <end>\",\n          \"<start> the lungs are clear. there is hyperinflation of the lungs. there is no pleural effusion or pneumothora. the heart and mediastinum are normal. mild arthritic changes of the spine are present. <end>\",\n          \"<start> the lungs are clear. there is no pleural effusion or pneumothora. the heart is not significantly enlarged. there are atherosclerotic changes of the aorta. there are severe arthritic changes of the with mild arthritic changes of the thoracic spine. <end>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dec_ip\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2548,\n        \"samples\": [\n          \"<start> the heart is top normal in size. the mediastinum is stable. the aorta is atherosclerotic. there are mild chronic changes without focal consolidation. no pleural effusion is seen.\",\n          \"<start> the lungs are clear. there is hyperinflation of the lungs. there is no pleural effusion or pneumothora. the heart and mediastinum are normal. mild arthritic changes of the spine are present.\",\n          \"<start> the lungs are clear. there is no pleural effusion or pneumothora. the heart is not significantly enlarged. there are atherosclerotic changes of the aorta. there are severe arthritic changes of the with mild arthritic changes of the thoracic spine.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dec_op\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2548,\n        \"samples\": [\n          \"the heart is top normal in size. the mediastinum is stable. the aorta is atherosclerotic. there are mild chronic changes without focal consolidation. no pleural effusion is seen. <end>\",\n          \"the lungs are clear. there is hyperinflation of the lungs. there is no pleural effusion or pneumothora. the heart and mediastinum are normal. mild arthritic changes of the spine are present. <end>\",\n          \"the lungs are clear. there is no pleural effusion or pneumothora. the heart is not significantly enlarged. there are atherosclerotic changes of the aorta. there are severe arthritic changes of the with mild arthritic changes of the thoracic spine. <end>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(data.values , test_size = 0.2 )\n"
      ],
      "metadata": {
        "id": "tr6LV_GU_7h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqAgHXHvAD-d",
        "outputId": "665b774f-eb02-45af-eda8-6da079253aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2669, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvLFHV3DAF7Q",
        "outputId": "0c13fdc6-7903-4b35-8fb6-522575de484c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(668, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[:-19, :]\n",
        "X_test = X_test[:-18, :]\n"
      ],
      "metadata": {
        "id": "LMMl1RlVAI14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = Tokenizer( filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n',oov_token='OOV')\n",
        "t1.fit_on_texts(X_train[:,5])\n",
        "\n",
        "t1.word_index['<pad>'] = 0\n",
        "t1.index_word[0] = '<pad>'\n",
        "vocab_size_imp = len(t1.word_index) + 1\n",
        "\n",
        "dec_inp = t1.texts_to_sequences(X_train[:,6])\n",
        "\n",
        "dec_inp = pad_sequences(dec_inp, maxlen=98, padding='post')\n",
        "\n",
        "dec_inp_cv = t1.texts_to_sequences(X_test[:,6])\n",
        "\n",
        "dec_inp_cv = pad_sequences(dec_inp_cv, maxlen=98, padding='post')\n",
        "\n",
        "dec_op = t1.texts_to_sequences(X_train[:,7])\n",
        "\n",
        "dec_op = pad_sequences(dec_op, maxlen=98, padding='post')\n",
        "\n",
        "dec_op_cv = t1.texts_to_sequences(X_test[:,7])\n",
        "\n",
        "dec_op_cv = pad_sequences(dec_op_cv, maxlen=98, padding='post')\n"
      ],
      "metadata": {
        "id": "_5RkD1jnAK3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_imp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO_kGpaOAMbd",
        "outputId": "bbfc39f6-08ef-4fce-f125-31cd811d3d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1826"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imp1 = {}\n",
        "imp2 = {}\n",
        "for key,value in t1.word_index.items():\n",
        "  imp1[value] = key\n",
        "  imp2[key] = value\n"
      ],
      "metadata": {
        "id": "I6NptH5cAP5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.dense1 = Dense(512)\n",
        "        self.d1 = Dropout(0.5)\n",
        "\n",
        "\n",
        "    def call(self,image_data):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        self.image_data = image_data\n",
        "        self.enc_out = self.dense1(self.image_data)\n",
        "        self.enc_out =self.d1(self.enc_out )\n",
        "\n",
        "\n",
        "        return self.enc_out\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BjaFxpg8ARw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Decoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size = lstm_size\n",
        "        self.d2  = Dropout(0.3)\n",
        "        self.dec_emb = Embedding(out_vocab_size,300,trainable = True)            #(None , 12,embedding_size)\n",
        "        self.dec_lstm = LSTM(self.lstm_size, return_sequences=True, name=\"Decoder_LSTM\")  #(None , 12,lstm_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def call(self,input_sequence):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "\n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        #print(\"DECODER ==> INPUT SQUENCES SHAPE :\",target_sentances.shape)\n",
        "        self.input_sequence = input_sequence\n",
        "\n",
        "        self.target_embedd           = self.dec_emb (self.input_sequence)\n",
        "        self.target_embedd =self.d2(self.target_embedd )\n",
        "        #print(\"WE ARE INITIALIZING DECODER WITH ENCODER STATES :\",state_h.shape, state_c.shape)\n",
        "        lstm_output      = self.dec_lstm(self.target_embedd)\n",
        "\n",
        "        return lstm_output\n",
        "\n"
      ],
      "metadata": {
        "id": "mDgV-eVKATOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_decoder(Model):\n",
        "\n",
        "    #def __init__(self,*params):\n",
        "    def __init__(self,out_vocab_size,embedding_size_d,lstm_size_d,input_length_d,batch_size):\n",
        "\n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_size_d = embedding_size_d\n",
        "        self.lstm_size_d = lstm_size_d\n",
        "        self.input_length_d = input_length_d\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.encoder = Encoder()\n",
        "\n",
        "        self.decoder = Decoder(out_vocab_size , embedding_size_d, lstm_size_d,input_length_d )\n",
        "        self.dense   = TimeDistributed(Dense(self.out_vocab_size, activation='softmax'))\n",
        "        self.d3 = Dropout(0.3)\n",
        "\n",
        "\n",
        "    #def call(self,*params):\n",
        "    def call(self,data):\n",
        "\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer\n",
        "\n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        self.input1,self.input2 = data[0], data[1]\n",
        "        print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
        "        self.encoder_output = self.encoder(self.input1)\n",
        "        print(\"-\"*27)\n",
        "        #print(\"ENCODER ==> OUTPUT SHAPE\",self.encoder_output.shape)\n",
        "        #print(\"ENCODER ==> HIDDEN STATE SHAPE\",self.encoder_h.shape)\n",
        "        #print(\"ENCODER ==> CELL STATE SHAPE\", self.encoder_c.shape)\n",
        "        print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
        "        self.decoder_output  = self.decoder(self.input2)\n",
        "        #self.decoder_output =Dropout(0.3)(self.decoder_output)\n",
        "        self.add=tf.keras.layers.Add()([self.encoder_output, self.decoder_output])\n",
        "        self.add =self.d3(self.add)\n",
        "\n",
        "        output         = self.dense(self.add)\n",
        "        print(\"-\"*27)\n",
        "        print(\"FINAL OUTPUT SHAPE\",output.shape)\n",
        "        print(\"=\"*50)\n",
        "        return output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0D259hfFAUtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an object of encoder_decoder Model class,\n",
        "# Compile the model and fit the model\n",
        "model1 = Encoder_decoder(vocab_size_imp,300,512,36,50)\n"
      ],
      "metadata": {
        "id": "C0aiA8V_AXQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoint\n"
      ],
      "metadata": {
        "id": "ParxfDr_AZEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n"
      ],
      "metadata": {
        "id": "kWkT7i3fAaxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = cwd + '/' + 'checkpoint' + '/'\n"
      ],
      "metadata": {
        "id": "nkUw8PV7Abrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JdLx7pwnAc1_",
        "outputId": "543f5680-1576-4144-9cbb-d95bcc2ffced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/checkpoint/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    verbose = 1,\n",
        "    mode='min',\n",
        "    save_best_only=True)\n"
      ],
      "metadata": {
        "id": "OGCFJB8AAd4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n"
      ],
      "metadata": {
        "id": "tYdbbasRAe-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8,mode = 'min',verbose = 1,\n",
        "                              patience=1, min_lr=0.0001)\n"
      ],
      "metadata": {
        "id": "sfAOyRa1Agf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model1.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics = 'accuracy')\n"
      ],
      "metadata": {
        "id": "Qu7GOYfoAhsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inp = np.vstack(X_train[:,4]).astype(float)\n",
        "test_inp = np.vstack(X_test[:,4]).astype(float)\n"
      ],
      "metadata": {
        "id": "q9ESydlgAlNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit([train_inp,dec_inp ],dec_op ,validation_data= ([test_inp, dec_inp_cv],dec_op_cv),batch_size= 25,epochs  = 30,callbacks=[reduce_lr,model_checkpoint_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzH6RIBpAnEZ",
        "outputId": "fe5377ea-0441-49ee-c053-b2137b4b856e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "==================== ENCODER ====================\n",
            "---------------------------\n",
            "==================== DECODER ====================\n",
            "---------------------------\n",
            "FINAL OUTPUT SHAPE (25, 98, 1826)\n",
            "==================================================\n",
            "==================== ENCODER ====================\n",
            "---------------------------\n",
            "==================== DECODER ====================\n",
            "---------------------------\n",
            "FINAL OUTPUT SHAPE (25, 98, 1826)\n",
            "==================================================\n",
            "106/106 [==============================] - ETA: 0s - loss: 1.9919 - accuracy: 0.6744==================== ENCODER ====================\n",
            "---------------------------\n",
            "==================== DECODER ====================\n",
            "---------------------------\n",
            "FINAL OUTPUT SHAPE (25, 98, 1826)\n",
            "==================================================\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.63379, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 24s 149ms/step - loss: 1.9919 - accuracy: 0.6744 - val_loss: 1.6338 - val_accuracy: 0.6947 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 1.5825 - accuracy: 0.7011\n",
            "Epoch 2: val_loss improved from 1.63379 to 1.43808, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 1.5825 - accuracy: 0.7011 - val_loss: 1.4381 - val_accuracy: 0.7219 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "104/106 [============================>.] - ETA: 0s - loss: 1.3153 - accuracy: 0.7455\n",
            "Epoch 3: val_loss improved from 1.43808 to 1.08684, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 1.3110 - accuracy: 0.7463 - val_loss: 1.0868 - val_accuracy: 0.7891 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "104/106 [============================>.] - ETA: 0s - loss: 0.9976 - accuracy: 0.8009\n",
            "Epoch 4: val_loss improved from 1.08684 to 0.87298, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 0.9979 - accuracy: 0.8009 - val_loss: 0.8730 - val_accuracy: 0.8222 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.8393 - accuracy: 0.8263\n",
            "Epoch 5: val_loss improved from 0.87298 to 0.77007, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 0.8393 - accuracy: 0.8263 - val_loss: 0.7701 - val_accuracy: 0.8428 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.7483 - accuracy: 0.8407\n",
            "Epoch 6: val_loss improved from 0.77007 to 0.71373, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 0.7479 - accuracy: 0.8408 - val_loss: 0.7137 - val_accuracy: 0.8547 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.8507\n",
            "Epoch 7: val_loss improved from 0.71373 to 0.67961, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.6852 - accuracy: 0.8503 - val_loss: 0.6796 - val_accuracy: 0.8610 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.8581\n",
            "Epoch 8: val_loss improved from 0.67961 to 0.66519, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.6386 - accuracy: 0.8580 - val_loss: 0.6652 - val_accuracy: 0.8644 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.5971 - accuracy: 0.8641\n",
            "Epoch 9: val_loss improved from 0.66519 to 0.63508, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5969 - accuracy: 0.8642 - val_loss: 0.6351 - val_accuracy: 0.8681 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.8691\n",
            "Epoch 10: val_loss improved from 0.63508 to 0.62231, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5658 - accuracy: 0.8691 - val_loss: 0.6223 - val_accuracy: 0.8718 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.8743\n",
            "Epoch 11: val_loss improved from 0.62231 to 0.61911, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.5345 - accuracy: 0.8744 - val_loss: 0.6191 - val_accuracy: 0.8729 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.5104 - accuracy: 0.8787\n",
            "Epoch 12: val_loss improved from 0.61911 to 0.61017, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5096 - accuracy: 0.8789 - val_loss: 0.6102 - val_accuracy: 0.8753 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.4851 - accuracy: 0.8833\n",
            "Epoch 13: val_loss improved from 0.61017 to 0.60626, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.4840 - accuracy: 0.8836 - val_loss: 0.6063 - val_accuracy: 0.8751 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.8868\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.60626\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4639 - accuracy: 0.8868 - val_loss: 0.6132 - val_accuracy: 0.8752 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.4325 - accuracy: 0.8934\n",
            "Epoch 15: val_loss improved from 0.60626 to 0.59777, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.4325 - accuracy: 0.8934 - val_loss: 0.5978 - val_accuracy: 0.8784 - lr: 8.0000e-04\n",
            "Epoch 16/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.4122 - accuracy: 0.8969\n",
            "Epoch 16: val_loss improved from 0.59777 to 0.59216, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 0.4128 - accuracy: 0.8967 - val_loss: 0.5922 - val_accuracy: 0.8782 - lr: 8.0000e-04\n",
            "Epoch 17/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8995\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.59216\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3987 - accuracy: 0.8995 - val_loss: 0.5940 - val_accuracy: 0.8779 - lr: 8.0000e-04\n",
            "Epoch 18/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.9046\n",
            "Epoch 18: val_loss improved from 0.59216 to 0.58800, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3771 - accuracy: 0.9045 - val_loss: 0.5880 - val_accuracy: 0.8805 - lr: 6.4000e-04\n",
            "Epoch 19/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.9072\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.58800\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3635 - accuracy: 0.9072 - val_loss: 0.5913 - val_accuracy: 0.8801 - lr: 6.4000e-04\n",
            "Epoch 20/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.9117\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.58800\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.3448 - accuracy: 0.9117 - val_loss: 0.5888 - val_accuracy: 0.8803 - lr: 5.1200e-04\n",
            "Epoch 21/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.9151\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.58800\n",
            "106/106 [==============================] - 3s 29ms/step - loss: 0.3286 - accuracy: 0.9151 - val_loss: 0.5886 - val_accuracy: 0.8807 - lr: 4.0960e-04\n",
            "Epoch 22/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.3164 - accuracy: 0.9178\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.58800\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3161 - accuracy: 0.9179 - val_loss: 0.5891 - val_accuracy: 0.8807 - lr: 3.2768e-04\n",
            "Epoch 23/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.9208\n",
            "Epoch 23: val_loss improved from 0.58800 to 0.58736, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3057 - accuracy: 0.9208 - val_loss: 0.5874 - val_accuracy: 0.8815 - lr: 2.6214e-04\n",
            "Epoch 24/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.9220\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.58736\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3011 - accuracy: 0.9220 - val_loss: 0.5888 - val_accuracy: 0.8816 - lr: 2.6214e-04\n",
            "Epoch 25/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.9243\n",
            "Epoch 25: val_loss improved from 0.58736 to 0.58719, saving model to /content/checkpoint/\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.2924 - accuracy: 0.9243 - val_loss: 0.5872 - val_accuracy: 0.8819 - lr: 2.0972e-04\n",
            "Epoch 26/30\n",
            "104/106 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.9253\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.58719\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.2892 - accuracy: 0.9250 - val_loss: 0.5902 - val_accuracy: 0.8815 - lr: 2.0972e-04\n",
            "Epoch 27/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.9264\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.58719\n",
            "106/106 [==============================] - 3s 28ms/step - loss: 0.2833 - accuracy: 0.9264 - val_loss: 0.5895 - val_accuracy: 0.8813 - lr: 1.6777e-04\n",
            "Epoch 28/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.9274\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.58719\n",
            "106/106 [==============================] - 3s 29ms/step - loss: 0.2785 - accuracy: 0.9274 - val_loss: 0.5889 - val_accuracy: 0.8816 - lr: 1.3422e-04\n",
            "Epoch 29/30\n",
            "106/106 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.9286\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.58719\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.2741 - accuracy: 0.9286 - val_loss: 0.5900 - val_accuracy: 0.8817 - lr: 1.0737e-04\n",
            "Epoch 30/30\n",
            "105/106 [============================>.] - ETA: 0s - loss: 0.2724 - accuracy: 0.9295\n",
            "Epoch 30: val_loss did not improve from 0.58719\n",
            "106/106 [==============================] - 3s 28ms/step - loss: 0.2717 - accuracy: 0.9297 - val_loss: 0.5897 - val_accuracy: 0.8814 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aea9d25ed40>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_model):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model1 predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model1.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  input_sentence = input_model\n",
        "\n",
        "  encoder_output= model1.layers[0](input_sentence)#,self.initial_state)\n",
        "  encoder_output = model1.layers[0].d1(encoder_output)\n",
        "\n",
        "  cur_vec = np.ones((1, 1)) * imp2['<start>'] # Here replace with index of <start> in the english vocab\n",
        "  pred = []\n",
        "  predicted_senence = \"<start>\"\n",
        "  for i in range(20):\n",
        "    cur_emb = model1.layers[1].dec_emb(cur_vec)\n",
        "    cur_emb = model1.layers[1].d2(cur_emb)\n",
        "    infe_output= model1.layers[1].dec_lstm(cur_emb)\n",
        "    infe_output=tf.keras.layers.Add()([encoder_output, infe_output])\n",
        "    infe_output=model1.layers[2](infe_output)\n",
        "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
        "    pred.append(cur_vec[0][0])\n",
        "\n",
        "    predicted_senence = predicted_senence + ' ' + imp1[cur_vec[0][0]+1]\n",
        "    if(cur_vec[0][0] == imp2['<end>'] ):\n",
        "      break\n",
        "  return predicted_senence.strip()\n",
        "\n",
        "#max_length = int(padlength)\n",
        "#max_length\n"
      ],
      "metadata": {
        "id": "gwxM65ZoArrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 36\n",
        "im_o = np.vstack(X_test[:,4][num]).astype(float)\n",
        "tex_o = X_test[:,5][num]\n",
        "print(\"Original Sentence is : \",tex_o)\n",
        "print(\"Predicted sentence: \",predict(im_o))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocFReOoZBSHi",
        "outputId": "be1471a0-16b7-4c5d-9847-8f4a8ec504de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence is :  <start> clear lungs. normal heart. no pneumothora. no pleural effusion. old right rib fractures. <end>\n",
            "Predicted sentence:  <start> no focal is with appear size clear or pulmonary of or pulmonary of or pulmonary of or pulmonary of or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = 90\n",
        "im_o = np.vstack(X_test[:,4][num]).astype(float)\n",
        "tex_o = X_test[:,5][num]\n",
        "print(\"Original Sentence is : \",tex_o)\n",
        "print(\"Predicted sentence: \",predict(im_o))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS-LmqtvBV6r",
        "outputId": "060b7423-4641-4908-c348-8829a131bd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence is :  <start> the heart is normal in size. the mediastinum is unremarkable. there is slight elevation of left hemidiaphragm with left basilar subsegmental atelectasis. the lungs are otherwise grossly clear. <end>\n",
            "Predicted sentence:  <start> no left clear. <start> opacities. in heart lungs within pleural vasculature noted. <start> opacities. in heart lungs within pleural vasculature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = 102\n",
        "im_o = np.vstack(X_test[:,4][num]).astype(float)\n",
        "tex_o = X_test[:,5][num]\n",
        "print(\"Original Sentence is : \",tex_o)\n",
        "print(\"Predicted sentence: \",predict(im_o))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4LSidkHBauN",
        "outputId": "9ede9356-2b22-454c-9f57-ff9ca148e3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence is :  <start> the cardiomediastinal silhouette is within normal limits for size and contour. the lungs are normally inflated without evidence of focal airspace disease, pleural effusion, or pneumothora. osseous structures are within normal limits for patient age. <end>\n",
            "Predicted sentence:  <start> no focal is airspace normal <start> opacities. lung chest. from no focal is airspace normal <start> opacities. lung chest. from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = 0\n",
        "\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "  im_o = np.vstack(X_test[:,4][i]).astype(float)\n",
        "  pred = predict(im_o)\n",
        "  org= X_test[:,5][i]\n",
        "\n",
        "  b=  b + bleu.sentence_bleu([org.split()], pred.split() )\n",
        "\n",
        "print(\"Bleu score is : \",b/X_test.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvJu-YSPBgcb",
        "outputId": "befcc012-1f0c-49d1-d5de-3c215141c8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu score is :  1.4425136149869226e-80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Qf0zRocB0l2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}