{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be45d2da-a9f3-4f0f-bebf-af89407d6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Class: Prepares the input image data.\n",
    "# Attention Class: Computes attention scores between decoder hidden states and encoder outputs.\n",
    "# OneStepDecoder Class: Handles decoding one step at a time, integrating attention.\n",
    "# Decoder Class: Utilizes OneStepDecoder for decoding entire sequences.\n",
    "# encoder_decoder Class: Combines Encoder and Decoder into a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "060dbfdc-8934-4cc1-94d9-bdeebee4cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model:\n",
    "\n",
    "# Define optimizer, loss function, and metrics for training.\n",
    "# Compile the encoder_decoder model.\n",
    "# Fit Model (model_1.fit):\n",
    "\n",
    "# Train the model using training data (train_inp, dec_inp, dec_op).\n",
    "# Validate using testing data (test_inp, dec_inp_cv, dec_op_cv).\n",
    "# Callbacks such as ModelCheckpoint and ReduceLROnPlateau are used for monitoring and optimization.\n",
    "# Step 4: Generating Captions\n",
    "# Generate Caption Example:\n",
    "# After training, to generate a caption for a new image:\n",
    "# Initialize with a start token (<start>).\n",
    "# Pass through the decoder (model_1.decoder) iteratively.\n",
    "# Use the OneStepDecoder to predict each subsequent token until an end token (<end>) or maximum length is reached.\n",
    "# Flow of Classes in Execution\n",
    "# Data Preparation Phase:\n",
    "\n",
    "# Tokenizer is used to prepare text data (findings_total) for training.\n",
    "# Sequences are padded to ensure consistent input size.\n",
    "# Model Definition Phase:\n",
    "\n",
    "# Encoder (Encoder): Processes image features (train_inp) to create initial context.\n",
    "# Attention (Attention): Calculates attention weights based on decoder state and encoder output.\n",
    "# One Step Decoder (OneStepDecoder): Generates predictions and updates states at each timestep.\n",
    "# Decoder (Decoder): Integrates OneStepDecoder to generate entire output sequence.\n",
    "# Training Phase:\n",
    "\n",
    "# Model (encoder_decoder): Integrates encoder and decoder logic for end-to-end training.\n",
    "# Callbacks: Monitors and optimizes training progress (ModelCheckpoint, ReduceLROnPlateau).\n",
    "# Caption Generation Phase:\n",
    "\n",
    "# Inference: Uses trained model to predict captions for new images.\n",
    "# Tokenization: Converts predicted token IDs back to words using reverse mapping (imp1).\n",
    "# This structured flow ensures each component (Encoder, Attention, Decoder) operates cohesively to generate accurate captions based on image features, demonstrating a clear progression from data preparation through model execution and application.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf35683-94a9-4b78-bef5-1c747389b65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c8a2d-a1c7-4769-9b04-7f0949a953e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a548917-e0fe-4f8f-8833-f1fd3d3829e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 23:35:10.818209: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-26 23:35:10.818300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-26 23:35:10.843560: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-26 23:35:10.901725: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 23:35:11.843125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done importing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l2\n",
    "import cv2 as cv\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow import concat\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM,Layer,Dropout,GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import repeat\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"done importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7368efaa-3151-48a2-bda7-c3860c02e0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encod.zip',\n",
       " 'Test_Data.csv',\n",
       " 'CV_Data.csv',\n",
       " 'Image_features_attention.pickle',\n",
       " 'model_with_accu.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'LLM_main1.ipynb',\n",
       " 'log.zip',\n",
       " 'attention_v8_(1) (1).ipynb',\n",
       " 'log',\n",
       " 'Untitled.ipynb',\n",
       " 'checkpoint',\n",
       " 'NLMCXR_png',\n",
       " 'untitled3.py',\n",
       " 'processed.pkl',\n",
       " 'Train_Data.csv',\n",
       " 'LLM1.ipynb',\n",
       " 'encoder_decoder_model.keras',\n",
       " 'NLMCXR_reports',\n",
       " 't1.pickle',\n",
       " 'encod',\n",
       " 'chexnet1.pptx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab92cd9-57af-4ccd-bb5d-dd44944fc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab880100-6417-45f0-a301-cb44cd7b83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('/home/professor/Downloads/fromgit/single_image_final_1024.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5256b4c-889c-483c-83d4-9ba48a2e1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data.values , test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac107a0e-b9d1-4916-81c1-2de739242a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3035, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda7fb49-1334-4988-b8ce-07b4ef4fe31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>uid</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>image_features</th>\n",
       "      <th>findings_total</th>\n",
       "      <th>dec_ip</th>\n",
       "      <th>dec_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>1</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "      <td>[[0.00026644140598364174, 0.001953634200617671...</td>\n",
       "      <td>&lt;start&gt; the cardiac silhouette and mediastinum...</td>\n",
       "      <td>&lt;start&gt; the cardiac silhouette and mediastinum...</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>2</td>\n",
       "      <td>borderline cardiomegaly. midline sternotomy . ...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "      <td>[[0.00022730983619112521, 0.001471916912123561...</td>\n",
       "      <td>&lt;start&gt; borderline cardiomegaly. midline stern...</td>\n",
       "      <td>&lt;start&gt; borderline cardiomegaly. midline stern...</td>\n",
       "      <td>borderline cardiomegaly. midline sternotomy . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>3</td>\n",
       "      <td>no displaced rib fractures, pneumothora, or pl...</td>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "      <td>[[0.00037261098623275757, 0.001325369114056229...</td>\n",
       "      <td>&lt;start&gt; no displaced rib fractures, pneumothor...</td>\n",
       "      <td>&lt;start&gt; no displaced rib fractures, pneumothor...</td>\n",
       "      <td>no displaced rib fractures, pneumothora, or pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_IM-2050-1001.dcm.png</td>\n",
       "      <td>4</td>\n",
       "      <td>there are diffuse bilateral interstitial and a...</td>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "      <td>[[7.35483699827455e-05, 0.0012481726007536054,...</td>\n",
       "      <td>&lt;start&gt; there are diffuse bilateral interstiti...</td>\n",
       "      <td>&lt;start&gt; there are diffuse bilateral interstiti...</td>\n",
       "      <td>there are diffuse bilateral interstitial and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_IM-2117-1003002.dcm.png</td>\n",
       "      <td>5</td>\n",
       "      <td>the cardiomediastinal silhouette and pulmonary...</td>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "      <td>[[0.0005863018450327218, 0.0017833115998655558...</td>\n",
       "      <td>&lt;start&gt; the cardiomediastinal silhouette and p...</td>\n",
       "      <td>&lt;start&gt; the cardiomediastinal silhouette and p...</td>\n",
       "      <td>the cardiomediastinal silhouette and pulmonary...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename  uid  \\\n",
       "0     1_IM-0001-4001.dcm.png    1   \n",
       "1     2_IM-0652-1001.dcm.png    2   \n",
       "2     3_IM-1384-1001.dcm.png    3   \n",
       "3     4_IM-2050-1001.dcm.png    4   \n",
       "4  5_IM-2117-1003002.dcm.png    5   \n",
       "\n",
       "                                            findings  \\\n",
       "0  the cardiac silhouette and mediastinum size ar...   \n",
       "1  borderline cardiomegaly. midline sternotomy . ...   \n",
       "2  no displaced rib fractures, pneumothora, or pl...   \n",
       "3  there are diffuse bilateral interstitial and a...   \n",
       "4  the cardiomediastinal silhouette and pulmonary...   \n",
       "\n",
       "                                          impression  \\\n",
       "0                               Normal chest x-XXXX.   \n",
       "1                       No acute pulmonary findings.   \n",
       "2  No displaced rib fractures, pneumothorax, or p...   \n",
       "3  1. Bullous emphysema and interstitial fibrosis...   \n",
       "4              No acute cardiopulmonary abnormality.   \n",
       "\n",
       "                                      image_features  \\\n",
       "0  [[0.00026644140598364174, 0.001953634200617671...   \n",
       "1  [[0.00022730983619112521, 0.001471916912123561...   \n",
       "2  [[0.00037261098623275757, 0.001325369114056229...   \n",
       "3  [[7.35483699827455e-05, 0.0012481726007536054,...   \n",
       "4  [[0.0005863018450327218, 0.0017833115998655558...   \n",
       "\n",
       "                                      findings_total  \\\n",
       "0  <start> the cardiac silhouette and mediastinum...   \n",
       "1  <start> borderline cardiomegaly. midline stern...   \n",
       "2  <start> no displaced rib fractures, pneumothor...   \n",
       "3  <start> there are diffuse bilateral interstiti...   \n",
       "4  <start> the cardiomediastinal silhouette and p...   \n",
       "\n",
       "                                              dec_ip  \\\n",
       "0  <start> the cardiac silhouette and mediastinum...   \n",
       "1  <start> borderline cardiomegaly. midline stern...   \n",
       "2  <start> no displaced rib fractures, pneumothor...   \n",
       "3  <start> there are diffuse bilateral interstiti...   \n",
       "4  <start> the cardiomediastinal silhouette and p...   \n",
       "\n",
       "                                              dec_op  \n",
       "0  the cardiac silhouette and mediastinum size ar...  \n",
       "1  borderline cardiomegaly. midline sternotomy . ...  \n",
       "2  no displaced rib fractures, pneumothora, or pl...  \n",
       "3  there are diffuse bilateral interstitial and a...  \n",
       "4  the cardiomediastinal silhouette and pulmonary...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bc91e0a-30bd-42b9-b111-c0c9b3e9fd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[0][\"image_features\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "034cf83b-a0f9-4cc7-8e4b-bc7866f3d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir = '/home/professor/Downloads/fromgit/NLMCXR_png/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4668e58-fd99-419f-b170-94856f80d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['filename'] = data['image1'].str.replace('/content/png/', maindir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c0b1e0-fca4-4061-b3d4-25d4ff6a3e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/professor/Downloads/fromgit/NLMCXR_png/CXR3556_IM-1741-1001-0001.png'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]['image1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e789790-5ed6-4595-8e2b-234aa5744d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:-19, :]\n",
    "X_test = X_test[:-18, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24c4517-2351-43de-936f-40358c59ce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2650, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1305ba37-98a3-4c24-aecb-fd01b07b1b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4aec23f-cfc4-4d3b-aa42-c404cd3845c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'image1', 'image2', 'findings', 'image_features',\n",
       "       'findings_total', 'dec_ip', 'dec_op'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf0cc0f-42d2-4dd7-b701-e56be05ab02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1 = Tokenizer( filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n',oov_token='OOV')\n",
    "t1.fit_on_texts(X_train[:,5])\n",
    "vocab_size_imp = len(t1.word_index) + 1\n",
    "\n",
    "dec_inp = t1.texts_to_sequences(X_train[:,6])\n",
    "\n",
    "dec_inp = pad_sequences(dec_inp, maxlen=76, padding='post')\n",
    "\n",
    "dec_inp_cv = t1.texts_to_sequences(X_test[:,6])\n",
    "\n",
    "dec_inp_cv = pad_sequences(dec_inp_cv, maxlen=76, padding='post')\n",
    "\n",
    "dec_op = t1.texts_to_sequences(X_train[:,7])\n",
    "\n",
    "dec_op = pad_sequences(dec_op, maxlen=76, padding='post')\n",
    "\n",
    "dec_op_cv = t1.texts_to_sequences(X_test[:,7])\n",
    "\n",
    "dec_op_cv = pad_sequences(dec_op_cv, maxlen=76, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e265929-5e4e-4b47-ac49-11298587b2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 0, 0, 0],\n",
       "       [4, 5, 0, 0, 0, 0],\n",
       "       [6, 7, 8, 9, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# example\n",
    "sequences = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8, 9]\n",
    "]\n",
    "\n",
    "padded_sequences = pad_sequences(sequences, maxlen=6, padding='post')\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a1acb7a-a6d0-4380-9822-7567aed00a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OOV': 1,\n",
       " 'the': 2,\n",
       " 'no': 3,\n",
       " 'are': 4,\n",
       " 'is': 5,\n",
       " '<start>': 6,\n",
       " '<end>': 7,\n",
       " 'and': 8,\n",
       " 'pleural': 9,\n",
       " 'or': 10,\n",
       " 'of': 11,\n",
       " 'normal': 12,\n",
       " 'there': 13,\n",
       " 'heart': 14,\n",
       " 'lungs': 15,\n",
       " 'focal': 16,\n",
       " 'size': 17,\n",
       " 'within': 18,\n",
       " 'in': 19,\n",
       " 'pneumothora': 20,\n",
       " 'pulmonary': 21,\n",
       " 'effusion': 22,\n",
       " 'normal.': 23,\n",
       " 'pneumothora.': 24,\n",
       " 'effusion.': 25,\n",
       " 'limits.': 26,\n",
       " 'right': 27,\n",
       " 'silhouette': 28,\n",
       " 'mediastinal': 29,\n",
       " 'airspace': 30,\n",
       " 'clear.': 31,\n",
       " 'cardiomediastinal': 32,\n",
       " 'left': 33,\n",
       " 'acute': 34,\n",
       " 'clear': 35,\n",
       " 'consolidation': 36,\n",
       " 'lung': 37,\n",
       " 'with': 38,\n",
       " 'structures': 39,\n",
       " 'mediastinum': 40,\n",
       " 'unremarkable.': 41,\n",
       " 'changes': 42,\n",
       " 'thoracic': 43,\n",
       " 'bony': 44,\n",
       " 'a': 45,\n",
       " 'stable': 46,\n",
       " 'degenerative': 47,\n",
       " 'spine.': 48,\n",
       " 'without': 49,\n",
       " 'mild': 50,\n",
       " 'large': 51,\n",
       " 'appear': 52,\n",
       " 'osseous': 53,\n",
       " 'contours': 54,\n",
       " 'cardiac': 55,\n",
       " 'limits': 56,\n",
       " 'consolidation.': 57,\n",
       " 'size.': 58,\n",
       " 'calcified': 59,\n",
       " '.': 60,\n",
       " 'evidence': 61,\n",
       " 'vascularity': 62,\n",
       " 'for': 63,\n",
       " 'disease.': 64,\n",
       " 'visualized': 65,\n",
       " 'intact.': 66,\n",
       " 'abnormality.': 67,\n",
       " 'to': 68,\n",
       " 'upper': 69,\n",
       " 'opacity': 70,\n",
       " 'seen.': 71,\n",
       " 'contour.': 72,\n",
       " 'lateral': 73,\n",
       " 'vasculature': 74,\n",
       " 'disease': 75,\n",
       " 'effusions': 76,\n",
       " 'lower': 77,\n",
       " 'contour': 78,\n",
       " 'opacities': 79,\n",
       " 'air': 80,\n",
       " 'identified.': 81,\n",
       " 'bilaterally.': 82,\n",
       " 'grossly': 83,\n",
       " 'chest': 84,\n",
       " 'free': 85,\n",
       " 'noted.': 86,\n",
       " 'on': 87,\n",
       " 'prior': 88,\n",
       " 'lobe': 89,\n",
       " 'bilateral': 90,\n",
       " 'low': 91,\n",
       " 'aorta.': 92,\n",
       " 'effusions.': 93,\n",
       " 'both': 94,\n",
       " 'space': 95,\n",
       " 'present': 96,\n",
       " 'spine': 97,\n",
       " 'small': 98,\n",
       " 'thora': 99,\n",
       " 'hilar': 100,\n",
       " 'rib': 101,\n",
       " 'pneumothoraces.': 102,\n",
       " 'interstitial': 103,\n",
       " 'visible': 104,\n",
       " 'soft': 105,\n",
       " 'negative': 106,\n",
       " 'edema.': 107,\n",
       " 'volumes': 108,\n",
       " 'otherwise': 109,\n",
       " 'seen': 110,\n",
       " 'epanded.': 111,\n",
       " 'nodules': 112,\n",
       " 'findings.': 113,\n",
       " 'contours.': 114,\n",
       " 'aortic': 115,\n",
       " 'areas': 116,\n",
       " 'mildly': 117,\n",
       " 'stable.': 118,\n",
       " 'enlarged.': 119,\n",
       " 'silhouette.': 120,\n",
       " 'granuloma': 121,\n",
       " 'atelectasis': 122,\n",
       " 'vascular': 123,\n",
       " 'definite': 124,\n",
       " 'aorta': 125,\n",
       " 'infiltrate': 126,\n",
       " 'abnormalities.': 127,\n",
       " 'atelectasis.': 128,\n",
       " 'appearance.': 129,\n",
       " 'granulomatous': 130,\n",
       " 'which': 131,\n",
       " 'not': 132,\n",
       " 'unchanged': 133,\n",
       " 'frontal': 134,\n",
       " 'suspicious': 135,\n",
       " 'costophrenic': 136,\n",
       " 'at': 137,\n",
       " 'from': 138,\n",
       " 'minimal': 139,\n",
       " 'opacities.': 140,\n",
       " 'infiltrate.': 141,\n",
       " 'may': 142,\n",
       " 'central': 143,\n",
       " 'volumes.': 144,\n",
       " 'overlying': 145,\n",
       " 'spaces': 146,\n",
       " 'masses.': 147,\n",
       " 'lobe.': 148,\n",
       " 'again': 149,\n",
       " 'increased': 150,\n",
       " 'this': 151,\n",
       " 'lungs.': 152,\n",
       " 'consistent': 153,\n",
       " 'specifically': 154,\n",
       " 'have': 155,\n",
       " 'appears': 156,\n",
       " 'cardiomegaly.': 157,\n",
       " 'atherosclerotic': 158,\n",
       " 'patient': 159,\n",
       " 'base': 160,\n",
       " 'chronic': 161,\n",
       " 'chest.': 162,\n",
       " 'lymph': 163,\n",
       " 'suggest': 164,\n",
       " 'opacity.': 165,\n",
       " 'show': 166,\n",
       " 'noted': 167,\n",
       " 'inflated': 168,\n",
       " 'eamination': 169,\n",
       " 'surgical': 170,\n",
       " 'trachea': 171,\n",
       " 'alveolar': 172,\n",
       " 'findings': 173,\n",
       " 'sternotomy': 174,\n",
       " 'interval': 175,\n",
       " 'anterior': 176,\n",
       " 'cardio': 177,\n",
       " 'interval.': 178,\n",
       " 'has': 179,\n",
       " 'an': 180,\n",
       " 'tip': 181,\n",
       " 'scarring': 182,\n",
       " 'pneumonia.': 183,\n",
       " 'tissues': 184,\n",
       " 'be': 185,\n",
       " 'bone': 186,\n",
       " 'midline.': 187,\n",
       " 'normally': 188,\n",
       " 'clips': 189,\n",
       " 'posterior': 190,\n",
       " 'well': 191,\n",
       " 'basilar': 192,\n",
       " 'density': 193,\n",
       " 'present.': 194,\n",
       " 'skeletal': 195,\n",
       " 'edema': 196,\n",
       " 'moderate': 197,\n",
       " 'displaced': 198,\n",
       " 'prominent': 199,\n",
       " 'scattered': 200,\n",
       " 'patchy': 201,\n",
       " 'bibasilar': 202,\n",
       " 'scarring.': 203,\n",
       " 'infiltrates.': 204,\n",
       " 'base.': 205,\n",
       " 'views': 206,\n",
       " 'sided': 207,\n",
       " 'tortuous': 208,\n",
       " 'represent': 209,\n",
       " 'unchanged.': 210,\n",
       " 'bronchovascular': 211,\n",
       " 'previous': 212,\n",
       " 'calcifications': 213,\n",
       " 'th': 214,\n",
       " 'adenopathy': 215,\n",
       " 'over': 216,\n",
       " 'silhouettes': 217,\n",
       " 'appearance': 218,\n",
       " 'streaky': 219,\n",
       " 'view': 220,\n",
       " 'blunting': 221,\n",
       " 'typical': 222,\n",
       " 'vertebral': 223,\n",
       " 'nodular': 224,\n",
       " 'markings': 225,\n",
       " 'nodule': 226,\n",
       " 'fracture': 227,\n",
       " 'but': 228,\n",
       " 'change': 229,\n",
       " 'tortuosity': 230,\n",
       " 'fractures': 231,\n",
       " 'hyperepanded': 232,\n",
       " 'old': 233,\n",
       " 'multiple': 234,\n",
       " 'spondylosis.': 235,\n",
       " 'pneumonia': 236,\n",
       " 'compatible': 237,\n",
       " 'tissue': 238,\n",
       " 'hemidiaphragm.': 239,\n",
       " 'granuloma.': 240,\n",
       " 'cardiomegaly': 241,\n",
       " 'compared': 242,\n",
       " 't': 243,\n",
       " 'been': 244,\n",
       " 'as': 245,\n",
       " 'view.': 246,\n",
       " 'fractures.': 247,\n",
       " 'granulomas.': 248,\n",
       " 'prominence': 249,\n",
       " 'limited': 250,\n",
       " 'unremarkable': 251,\n",
       " 'diaphragm.': 252,\n",
       " 'cm': 253,\n",
       " 'enlarged': 254,\n",
       " 'obtained.': 255,\n",
       " 'catheter': 256,\n",
       " 'mid': 257,\n",
       " 'consolidations.': 258,\n",
       " 'tortuous.': 259,\n",
       " 'than': 260,\n",
       " 'bilaterally': 261,\n",
       " 'identified': 262,\n",
       " 'fracture.': 263,\n",
       " 'body': 264,\n",
       " 'consists': 265,\n",
       " 'radiographs': 266,\n",
       " 'vascularity.': 267,\n",
       " 'midlung': 268,\n",
       " 'significant': 269,\n",
       " 'hemidiaphragm': 270,\n",
       " 'throughout': 271,\n",
       " 'subsegmental': 272,\n",
       " 'deformity': 273,\n",
       " 'diffuse': 274,\n",
       " 'calcification': 275,\n",
       " 'also': 276,\n",
       " 'under': 277,\n",
       " 'area': 278,\n",
       " 'emphysema.': 279,\n",
       " 'granulomas': 280,\n",
       " 'thoracolumbar': 281,\n",
       " 'hyperepanded.': 282,\n",
       " 'abdomen': 283,\n",
       " 'pa': 284,\n",
       " 'crowding.': 285,\n",
       " 'age.': 286,\n",
       " 'was': 287,\n",
       " 'intraperitoneal': 288,\n",
       " 'infiltrates': 289,\n",
       " 'hiatal': 290,\n",
       " 'hyperinflated': 291,\n",
       " 'elevation': 292,\n",
       " 'reveal': 293,\n",
       " 'projecting': 294,\n",
       " 'perihilar': 295,\n",
       " 'middle': 296,\n",
       " 'demonstrate': 297,\n",
       " 'emphysematous': 298,\n",
       " 'multilevel': 299,\n",
       " 'fluid.': 300,\n",
       " 'secondary': 301,\n",
       " 'mm': 302,\n",
       " 'superior': 303,\n",
       " 'abnormality': 304,\n",
       " 'postsurgical': 305,\n",
       " 'changes.': 306,\n",
       " 'remain': 307,\n",
       " 'were': 308,\n",
       " 'hypoinflated': 309,\n",
       " 'flattening': 310,\n",
       " 'greater': 311,\n",
       " 'remains': 312,\n",
       " 'slightly': 313,\n",
       " 'distal': 314,\n",
       " 'intact': 315,\n",
       " 'venous': 316,\n",
       " 'versus': 317,\n",
       " 'due': 318,\n",
       " 'borderline': 319,\n",
       " 'ap': 320,\n",
       " 'most': 321,\n",
       " 'heart.': 322,\n",
       " 'leads': 323,\n",
       " 'any': 324,\n",
       " 'hernia.': 325,\n",
       " 'some': 326,\n",
       " 'configuration.': 327,\n",
       " 'images.': 328,\n",
       " 'osteophytes.': 329,\n",
       " 'represents': 330,\n",
       " 'representing': 331,\n",
       " 'arthritic': 332,\n",
       " 'aerated.': 333,\n",
       " 'widening.': 334,\n",
       " 'crowding': 335,\n",
       " 'study.': 336,\n",
       " 'study': 337,\n",
       " 'cervical': 338,\n",
       " 'similar': 339,\n",
       " 'disc': 340,\n",
       " 'thickening': 341,\n",
       " 'lung.': 342,\n",
       " 'eam.': 343,\n",
       " 'bases': 344,\n",
       " 'demonstrated.': 345,\n",
       " 'significantly': 346,\n",
       " 'dense': 347,\n",
       " 'apical': 348,\n",
       " 'suggesting': 349,\n",
       " 'line': 350,\n",
       " 'eamination.': 351,\n",
       " 'endplate': 352,\n",
       " 'appearing': 353,\n",
       " 'junction.': 354,\n",
       " 'epanded': 355,\n",
       " 'svc.': 356,\n",
       " 'near': 357,\n",
       " 'retrocardiac': 358,\n",
       " 'medial': 359,\n",
       " 'ape': 360,\n",
       " 'midthoracic': 361,\n",
       " 'eam': 362,\n",
       " 'evaluation': 363,\n",
       " 'along': 364,\n",
       " 'mediastinum.': 365,\n",
       " 'process.': 366,\n",
       " 'clavicle': 367,\n",
       " 'vasculature.': 368,\n",
       " 'bases.': 369,\n",
       " 'eventration': 370,\n",
       " 'biapical': 371,\n",
       " 'approimately': 372,\n",
       " 'mass': 373,\n",
       " 'fluid': 374,\n",
       " 'scoliosis': 375,\n",
       " 'descending': 376,\n",
       " 'abdomen.': 377,\n",
       " 'configuration': 378,\n",
       " 'densities': 379,\n",
       " 'severe': 380,\n",
       " 'left.': 381,\n",
       " 'low.': 382,\n",
       " 'joint': 383,\n",
       " 'picc': 384,\n",
       " 'elevated': 385,\n",
       " 'top': 386,\n",
       " 'partially': 387,\n",
       " 'by': 388,\n",
       " 'osteophytes': 389,\n",
       " 'persistent': 390,\n",
       " 'lucency': 391,\n",
       " 'curvature': 392,\n",
       " 'lumbar': 393,\n",
       " 'eternal': 394,\n",
       " 'possibly': 395,\n",
       " 'hyperinflation': 396,\n",
       " 'calcifications.': 397,\n",
       " 'healed': 398,\n",
       " 'nodule.': 399,\n",
       " 'demonstrated': 400,\n",
       " 'flattened': 401,\n",
       " 'ectasia': 402,\n",
       " 'since': 403,\n",
       " 'loss': 404,\n",
       " 'deformities': 405,\n",
       " 'congestion.': 406,\n",
       " 'several': 407,\n",
       " 'engorgement': 408,\n",
       " 'rib.': 409,\n",
       " 'somewhat': 410,\n",
       " 'detroscoliosis': 411,\n",
       " 'these': 412,\n",
       " 'post': 413,\n",
       " 'reveals': 414,\n",
       " 'suggestive': 415,\n",
       " 'midlung.': 416,\n",
       " 'sequela': 417,\n",
       " 'related': 418,\n",
       " 'ribs.': 419,\n",
       " 'body.': 420,\n",
       " 'tube': 421,\n",
       " 'diaphragm': 422,\n",
       " 'breast': 423,\n",
       " 'paratracheal': 424,\n",
       " 'overall': 425,\n",
       " 'cabg.': 426,\n",
       " 'removal': 427,\n",
       " 'enlargement': 428,\n",
       " 'ape.': 429,\n",
       " 'convincing': 430,\n",
       " 'prior.': 431,\n",
       " 'lobes.': 432,\n",
       " 'vague': 433,\n",
       " 'large.': 434,\n",
       " 'consolidations': 435,\n",
       " 'probable': 436,\n",
       " 'monitor': 437,\n",
       " 'previously': 438,\n",
       " 'hernia': 439,\n",
       " 'quadrant.': 440,\n",
       " 'hyperepansion': 441,\n",
       " 'airways': 442,\n",
       " 'infection.': 443,\n",
       " 'retrosternal': 444,\n",
       " 'change.': 445,\n",
       " 'midline': 446,\n",
       " 'could': 447,\n",
       " 'wall': 448,\n",
       " 'status': 449,\n",
       " 'moderately': 450,\n",
       " 'superimposed': 451,\n",
       " 'ribs': 452,\n",
       " 'however': 453,\n",
       " 'air.': 454,\n",
       " 'clips.': 455,\n",
       " 'humeral': 456,\n",
       " 'comparison': 457,\n",
       " 'projection.': 458,\n",
       " 'segment': 459,\n",
       " 'remote': 460,\n",
       " 'kyphosis.': 461,\n",
       " 'markings.': 462,\n",
       " 'parenchymal': 463,\n",
       " 'active': 464,\n",
       " 'two': 465,\n",
       " 'marked': 466,\n",
       " 'right.': 467,\n",
       " 'rounded': 468,\n",
       " 'hypoinflated.': 469,\n",
       " 'ct': 470,\n",
       " 'region': 471,\n",
       " 'measuring': 472,\n",
       " 'atrium.': 473,\n",
       " 'scar': 474,\n",
       " 'through': 475,\n",
       " 'technique.': 476,\n",
       " 'sized': 477,\n",
       " 'coronary': 478,\n",
       " 'age': 479,\n",
       " 'acromioclavicular': 480,\n",
       " 'atrial': 481,\n",
       " 'atrium': 482,\n",
       " 'that': 483,\n",
       " 'cholecystectomy': 484,\n",
       " 'first': 485,\n",
       " 'redemonstration': 486,\n",
       " 'given': 487,\n",
       " 'round': 488,\n",
       " 'masses': 489,\n",
       " 'widening': 490,\n",
       " 'improved': 491,\n",
       " 'volume': 492,\n",
       " 'diaphragms.': 493,\n",
       " 'one': 494,\n",
       " 'dual': 495,\n",
       " 'calcification.': 496,\n",
       " 'artery': 497,\n",
       " 'abnormal': 498,\n",
       " 'osteophyte': 499,\n",
       " 'bowel': 500,\n",
       " 'wedge': 501,\n",
       " 'sequelae': 502,\n",
       " 'aeration': 503,\n",
       " 'decreased': 504,\n",
       " 'fusion': 505,\n",
       " 'sulcus': 506,\n",
       " 'noncalcified': 507,\n",
       " 'note': 508,\n",
       " 'residual': 509,\n",
       " 'osteopenia': 510,\n",
       " 'underlying': 511,\n",
       " 'diaphragms': 512,\n",
       " 'unfolding': 513,\n",
       " 'postoperative': 514,\n",
       " 'eaggerated': 515,\n",
       " 'sternotomy.': 516,\n",
       " 'valve': 517,\n",
       " 'level': 518,\n",
       " 'jugular': 519,\n",
       " 'abnormalities': 520,\n",
       " 'foreign': 521,\n",
       " 'bodies': 522,\n",
       " 'shoulder': 523,\n",
       " 'atherosclerotic.': 524,\n",
       " 'calcific': 525,\n",
       " 'irregularity': 526,\n",
       " 'developed': 527,\n",
       " 'region.': 528,\n",
       " 'nipple': 529,\n",
       " 'subdiaphragmatic': 530,\n",
       " 'tortuosity.': 531,\n",
       " 'visualized.': 532,\n",
       " 'aspect': 533,\n",
       " 'abdominal': 534,\n",
       " 'formation': 535,\n",
       " 'it': 536,\n",
       " 'suggests': 537,\n",
       " 'bodies.': 538,\n",
       " 'pericardial': 539,\n",
       " 'ct.': 540,\n",
       " 'ventricle.': 541,\n",
       " 'obstructive': 542,\n",
       " 'osseus': 543,\n",
       " 'probably': 544,\n",
       " 'accentuated': 545,\n",
       " 'pacemaker': 546,\n",
       " 'structures.': 547,\n",
       " 'elevated.': 548,\n",
       " 'more': 549,\n",
       " 'measures': 550,\n",
       " 'hemidiaphragms': 551,\n",
       " 'obscuration': 552,\n",
       " 'overt': 553,\n",
       " 'scar.': 554,\n",
       " 'internal': 555,\n",
       " 'shoulder.': 556,\n",
       " 'hemidiaphragms.': 557,\n",
       " 'l': 558,\n",
       " 'correlate': 559,\n",
       " 'cavitary': 560,\n",
       " 'diameter.': 561,\n",
       " 'numerous': 562,\n",
       " 'proimal': 563,\n",
       " 'contrast': 564,\n",
       " 'calcified.': 565,\n",
       " 'associated': 566,\n",
       " 'peripheral': 567,\n",
       " 'habitus.': 568,\n",
       " 'discrete': 569,\n",
       " 'cabg': 570,\n",
       " 'hilum': 571,\n",
       " 'pectus': 572,\n",
       " 'pneumoperitoneum.': 573,\n",
       " 'kyphosis': 574,\n",
       " 'levoscoliosis': 575,\n",
       " 'enlargement.': 576,\n",
       " 'etensive': 577,\n",
       " 'deformity.': 578,\n",
       " 'fat': 579,\n",
       " 'cannot': 580,\n",
       " 'ascending': 581,\n",
       " 'generator': 582,\n",
       " 'cardiopulmonary': 583,\n",
       " 'relative': 584,\n",
       " 'lingula.': 585,\n",
       " 'demonstrates': 586,\n",
       " 'partial': 587,\n",
       " 'indicate': 588,\n",
       " 'thickening.': 589,\n",
       " 'development': 590,\n",
       " 'hyperinflation.': 591,\n",
       " 'known': 592,\n",
       " 'inferior': 593,\n",
       " 'involving': 594,\n",
       " 'amount': 595,\n",
       " 'hilum.': 596,\n",
       " 'aillary': 597,\n",
       " 'hyperlucent': 598,\n",
       " 'defined': 599,\n",
       " 'caliber.': 600,\n",
       " 'coarse': 601,\n",
       " 'stent.': 602,\n",
       " 'position.': 603,\n",
       " 'zone.': 604,\n",
       " 'subclavian': 605,\n",
       " 'overlie': 606,\n",
       " 'dilated': 607,\n",
       " 'fissure.': 608,\n",
       " 'opacification.': 609,\n",
       " 'dislocation.': 610,\n",
       " 'caval': 611,\n",
       " 'airspace.': 612,\n",
       " 'possible': 613,\n",
       " 'relatively': 614,\n",
       " 'apparent': 615,\n",
       " 'causing': 616,\n",
       " 'appreciated.': 617,\n",
       " 'lobes': 618,\n",
       " 'cholecystectomy.': 619,\n",
       " 'lesions': 620,\n",
       " 'tissues.': 621,\n",
       " 'bandlike': 622,\n",
       " 'deformities.': 623,\n",
       " 'between': 624,\n",
       " 'increase': 625,\n",
       " 'lesion': 626,\n",
       " 'ectatic': 627,\n",
       " 'early': 628,\n",
       " 'reflect': 629,\n",
       " 'healing': 630,\n",
       " 'bullet': 631,\n",
       " 'loops': 632,\n",
       " 'stomach': 633,\n",
       " 'nodules.': 634,\n",
       " 'adjacent': 635,\n",
       " 'shaped': 636,\n",
       " 'ill': 637,\n",
       " 'zone': 638,\n",
       " 'lingular': 639,\n",
       " 'projects': 640,\n",
       " 'blunted': 641,\n",
       " 'predominantly': 642,\n",
       " 'projection': 643,\n",
       " 'catheter.': 644,\n",
       " 'symmetric': 645,\n",
       " 'epected': 646,\n",
       " 'curvilinear': 647,\n",
       " 'head': 648,\n",
       " 'blunted.': 649,\n",
       " 'pattern': 650,\n",
       " 'node.': 651,\n",
       " 'history': 652,\n",
       " 'few': 653,\n",
       " 'quadrant': 654,\n",
       " 'wedging': 655,\n",
       " 'indeterminate': 656,\n",
       " 'apices.': 657,\n",
       " 'collection': 658,\n",
       " 'atherosclerosis.': 659,\n",
       " 'atherosclerosis': 660,\n",
       " 'injury.': 661,\n",
       " 'injury': 662,\n",
       " 'lumen': 663,\n",
       " 'cavoatrial': 664,\n",
       " 'joints': 665,\n",
       " 'shows': 666,\n",
       " 'adenopathy.': 667,\n",
       " 'ecluded.': 668,\n",
       " 'basal': 669,\n",
       " 'collections.': 670,\n",
       " 'posttraumatic': 671,\n",
       " 'detrocurvature': 672,\n",
       " 'rotated.': 673,\n",
       " 'studies.': 674,\n",
       " 'suprahilar': 675,\n",
       " 'hyperepansion.': 676,\n",
       " 'cm.': 677,\n",
       " 'obscured': 678,\n",
       " 'infrahilar': 679,\n",
       " 'detro': 680,\n",
       " 'arteries.': 681,\n",
       " 'fibrosis': 682,\n",
       " 'removed.': 683,\n",
       " 'pleura': 684,\n",
       " 'engorged.': 685,\n",
       " 'concerning': 686,\n",
       " 'spinal': 687,\n",
       " 'subcutaneous': 688,\n",
       " 'congestion': 689,\n",
       " 'fibrosis.': 690,\n",
       " 'sclerotic': 691,\n",
       " 'vein.': 692,\n",
       " 'opacification': 693,\n",
       " 'including': 694,\n",
       " 'only': 695,\n",
       " 'diffusely': 696,\n",
       " 'rotated': 697,\n",
       " 'below': 698,\n",
       " 'confluent': 699,\n",
       " 'lobar': 700,\n",
       " 'asymmetric': 701,\n",
       " 'fissure': 702,\n",
       " 'sutures': 703,\n",
       " 'slight': 704,\n",
       " 'lymphadenopathy.': 705,\n",
       " 'improvement': 706,\n",
       " 'overlies': 707,\n",
       " 'azygos': 708,\n",
       " 'icd': 709,\n",
       " 'gross': 710,\n",
       " 'silhouettes.': 711,\n",
       " 'radiograph.': 712,\n",
       " 'knee': 713,\n",
       " 'thora.': 714,\n",
       " 'projected': 715,\n",
       " 'question': 716,\n",
       " 'hip': 717,\n",
       " 'destructive': 718,\n",
       " 'process': 719,\n",
       " 'other': 720,\n",
       " 'cystic': 721,\n",
       " 'better': 722,\n",
       " 'radiographic': 723,\n",
       " 'diminished': 724,\n",
       " 'airways.': 725,\n",
       " 'remainder': 726,\n",
       " 'glenoid': 727,\n",
       " 'redemonstrated': 728,\n",
       " 'above': 729,\n",
       " 'parenchyma': 730,\n",
       " 'device': 731,\n",
       " 'epicardial': 732,\n",
       " 'fiation': 733,\n",
       " 'scan': 734,\n",
       " 'humerus.': 735,\n",
       " 'scoliosis.': 736,\n",
       " 'platelike': 737,\n",
       " 'maintained.': 738,\n",
       " 'tubing': 739,\n",
       " 'residuals': 740,\n",
       " 'eclude': 741,\n",
       " 'worse': 742,\n",
       " 'fusion.': 743,\n",
       " 'destruction.': 744,\n",
       " 'dish': 745,\n",
       " 'clavicle.': 746,\n",
       " 'bullae': 747,\n",
       " 'collapse': 748,\n",
       " 'terminating': 749,\n",
       " 'well.': 750,\n",
       " 'ecluded': 751,\n",
       " 'density.': 752,\n",
       " 'replacement.': 753,\n",
       " 'incompletely': 754,\n",
       " 'evaluated': 755,\n",
       " 'questionable': 756,\n",
       " 'tube.': 757,\n",
       " 'apices': 758,\n",
       " 'radiopaque': 759,\n",
       " 'differences': 760,\n",
       " 'bypass': 761,\n",
       " 'graft': 762,\n",
       " 'diameter': 763,\n",
       " 'tuberculosis.': 764,\n",
       " 'sternum.': 765,\n",
       " 'performed': 766,\n",
       " 'subtle': 767,\n",
       " 's': 768,\n",
       " 'tuberculous': 769,\n",
       " 'appreciated': 770,\n",
       " 'atelectatic': 771,\n",
       " 'node': 772,\n",
       " 'lordotic': 773,\n",
       " 'evaluation.': 774,\n",
       " 'neck': 775,\n",
       " 'radiograph': 776,\n",
       " 'dialysis': 777,\n",
       " 'irregular': 778,\n",
       " 'svc': 779,\n",
       " 'hyperlucency': 780,\n",
       " 'arteries': 781,\n",
       " 'artifact.': 782,\n",
       " 'coarsened': 783,\n",
       " 'location': 784,\n",
       " 'shadows': 785,\n",
       " 'stent': 786,\n",
       " 'artifact': 787,\n",
       " 'irregularities': 788,\n",
       " 'aerated': 789,\n",
       " 'does': 790,\n",
       " 'shift.': 791,\n",
       " 'space.': 792,\n",
       " 'resolution': 793,\n",
       " 'overlapping': 794,\n",
       " 'consolidating': 795,\n",
       " 'suture': 796,\n",
       " 'material': 797,\n",
       " 'surgery.': 798,\n",
       " 'resolved.': 799,\n",
       " 'now': 800,\n",
       " 'dislocations.': 801,\n",
       " 'pelvis': 802,\n",
       " 'narrowing': 803,\n",
       " 'characteristic': 804,\n",
       " 'increased.': 805,\n",
       " 'ij': 806,\n",
       " 'available': 807,\n",
       " 'filled': 808,\n",
       " 'ventricle': 809,\n",
       " 'high': 810,\n",
       " 'sclerosis': 811,\n",
       " 'images': 812,\n",
       " 'scan.': 813,\n",
       " 'prominence.': 814,\n",
       " 'pelvis.': 815,\n",
       " 'consolidative': 816,\n",
       " 'comparison.': 817,\n",
       " 'ventricular': 818,\n",
       " 'glenohumeral': 819,\n",
       " 'infectious': 820,\n",
       " 'technical': 821,\n",
       " 'factors': 822,\n",
       " 'cortical': 823,\n",
       " 't.': 824,\n",
       " 'tracheostomy': 825,\n",
       " 'scoliotic': 826,\n",
       " 'outside': 827,\n",
       " 'technique': 828,\n",
       " 'conveity': 829,\n",
       " 'demineralization.': 830,\n",
       " 'tips': 831,\n",
       " 'indeterminate.': 832,\n",
       " 'developing': 833,\n",
       " 'fat.': 834,\n",
       " 'its': 835,\n",
       " 'position': 836,\n",
       " 'obvious': 837,\n",
       " 'recent': 838,\n",
       " 'incidental': 839,\n",
       " 'aneurysm.': 840,\n",
       " 'corresponding': 841,\n",
       " 'renal': 842,\n",
       " 'flowing': 843,\n",
       " 'spurring': 844,\n",
       " 'eventration.': 845,\n",
       " 'retraction': 846,\n",
       " 'rightward': 847,\n",
       " 'complete': 848,\n",
       " 'ovoid': 849,\n",
       " 'junction': 850,\n",
       " 'humerus': 851,\n",
       " 'chronically': 852,\n",
       " 'detroscoliosis.': 853,\n",
       " 'hyperaerated': 854,\n",
       " 'positional.': 855,\n",
       " 'enteric': 856,\n",
       " 'overlap': 857,\n",
       " 'obscure': 858,\n",
       " 'third': 859,\n",
       " 'l.': 860,\n",
       " 'paraspinal': 861,\n",
       " 'strandy': 862,\n",
       " 'kyphotic': 863,\n",
       " 'single': 864,\n",
       " 'levels.': 865,\n",
       " 'posteriorly': 866,\n",
       " 'stimulator': 867,\n",
       " 'indistinct': 868,\n",
       " 'minimally': 869,\n",
       " 'splenic': 870,\n",
       " 'rectum.': 871,\n",
       " 'stool': 872,\n",
       " 'hemithora': 873,\n",
       " 'denser': 874,\n",
       " 'bronchi': 875,\n",
       " 'larger': 876,\n",
       " 'regions.': 877,\n",
       " 'approimating': 878,\n",
       " 'transverse': 879,\n",
       " 'prominent.': 880,\n",
       " 'redemonstrated.': 881,\n",
       " 'fifth': 882,\n",
       " 'clinically.': 883,\n",
       " 'distribution': 884,\n",
       " 'sided.': 885,\n",
       " 'fragment.': 886,\n",
       " 'tunneled': 887,\n",
       " 'feeding': 888,\n",
       " 'uncertain': 889,\n",
       " 'unfolded': 890,\n",
       " 'evaluated.': 891,\n",
       " 'limit': 892,\n",
       " 'unfolded.': 893,\n",
       " 'fourth': 894,\n",
       " 'placed': 895,\n",
       " 'centrally': 896,\n",
       " 'mitral': 897,\n",
       " 'senescent': 898,\n",
       " 'fragments': 899,\n",
       " 'portions': 900,\n",
       " 'knee.': 901,\n",
       " 'marginal': 902,\n",
       " 'bullous': 903,\n",
       " 'elements': 904,\n",
       " 'neck.': 905,\n",
       " 'lesions.': 906,\n",
       " 'placement': 907,\n",
       " 'non': 908,\n",
       " 'infection': 909,\n",
       " 'bilaterally.there': 910,\n",
       " 'subchondral': 911,\n",
       " 'femoral': 912,\n",
       " 'head.': 913,\n",
       " 'markers': 914,\n",
       " 'callus': 915,\n",
       " 'hiatus': 916,\n",
       " 'if': 917,\n",
       " 'cardiophrenic': 918,\n",
       " 'pattern.': 919,\n",
       " 'fissural': 920,\n",
       " 'greatest': 921,\n",
       " 'subcarinal': 922,\n",
       " 'views.': 923,\n",
       " 'remaining': 924,\n",
       " 'further': 925,\n",
       " 'like': 926,\n",
       " 'obtained': 927,\n",
       " 'considering': 928,\n",
       " 'fullness': 929,\n",
       " 'oval': 930,\n",
       " 'hyperinflated.': 931,\n",
       " 'three': 932,\n",
       " 'eaminations.': 933,\n",
       " 'shadows.': 934,\n",
       " 'about': 935,\n",
       " 'discoid': 936,\n",
       " 'ailla.': 937,\n",
       " 'eaggeration': 938,\n",
       " 'ivc': 939,\n",
       " 'procedure.': 940,\n",
       " 'dated': 941,\n",
       " 'joints.': 942,\n",
       " 'osteopenia.': 943,\n",
       " 'posterolateral': 944,\n",
       " 'prosthetic': 945,\n",
       " 'decreased.': 946,\n",
       " 'suggestion': 947,\n",
       " 'deep': 948,\n",
       " 'spondylosis': 949,\n",
       " 'would': 950,\n",
       " 'background': 951,\n",
       " 'sulci': 952,\n",
       " 'another': 953,\n",
       " 'lingula': 954,\n",
       " 'breast.': 955,\n",
       " 'ecavatum': 956,\n",
       " 'screw': 957,\n",
       " 'costochondral': 958,\n",
       " 'dislocation': 959,\n",
       " 'corticated': 960,\n",
       " 'margin': 961,\n",
       " 'ankle.': 962,\n",
       " 'cardia': 963,\n",
       " 'alignment': 964,\n",
       " 'markedly': 965,\n",
       " 'nondisplaced': 966,\n",
       " 'short': 967,\n",
       " 'reside': 968,\n",
       " 'gastrostomy': 969,\n",
       " 'containing': 970,\n",
       " 'airway': 971,\n",
       " 'imaging.': 972,\n",
       " 'series.': 973,\n",
       " 'hypertension.': 974,\n",
       " 'osteodystrophy': 975,\n",
       " 'densities.': 976,\n",
       " 'gastroesophageal': 977,\n",
       " 'idiopathic': 978,\n",
       " 'shape.': 979,\n",
       " 'ecept': 980,\n",
       " 'shielded.': 981,\n",
       " 'surrounding': 982,\n",
       " 'end.': 983,\n",
       " 'levoscoliosis.': 984,\n",
       " 'rotation.': 985,\n",
       " 'etremity': 986,\n",
       " 'rotation': 987,\n",
       " 'second': 988,\n",
       " 'already': 989,\n",
       " 'bronchial': 990,\n",
       " 'bronchitis.': 991,\n",
       " 'vertebroplasty': 992,\n",
       " 'largest': 993,\n",
       " 'osteopenic.': 994,\n",
       " 'margination.': 995,\n",
       " 'pneumomediastinum': 996,\n",
       " 'retained': 997,\n",
       " 'endotracheal': 998,\n",
       " 'recommend': 999,\n",
       " 'markers.': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb6dfbac-6b4c-42c4-ada5-7edafe651392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6 162  15   4  35  82  55   8  29 217   4  23  21  74   5  23   3  20\n",
      "  10   9  25   3  34  44  67 419  13   4   3 198 101 231  10 837 966 101\n",
      " 247 105 184  52  23   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(dec_inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142f70b-14c7-414d-883c-7e9b9be4ea72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fbbf6c-3d09-4144-a1bf-1bb96a76211e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6327366-33e2-4375-93c6-5296fac7a6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56c310-11db-4af3-af5f-d74c3c62d5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a70e1ec-677e-4d95-a182-8cc138b1d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('t1.pickle', 'wb') as handle:\n",
    "    pickle.dump(t1,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "557617f3-bdd7-4c70-94d2-ab4170880bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd27f273-ffa9-4198-ba37-baa5d575ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp1 = {}\n",
    "imp2 = {}\n",
    "for key,value in t1.word_index.items():\n",
    "  imp1[value] = key\n",
    "  imp2[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "377b516a-ac19-43e7-903f-5d09eb3f4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.dense = Dense(self.units,name = 'Enc_dense')\n",
    "\n",
    "    \n",
    "    def call(self,img):\n",
    "      '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "      '''\n",
    "      #enc_out = self.maxpool(tf.expand_dims(img,axis = 2))\n",
    "      enc_out = self.dense(img)\n",
    "      print(\"Enc_out = \", enc_out)\n",
    "      return enc_out\n",
    "\n",
    "\n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      self.batch_size  = batch_size\n",
    "\n",
    "      self.enc_h =tf.zeros((self.batch_size, self.units))\n",
    "\n",
    "      #self.enc_c = tf.zeros((self.batch_size, self.lstm_size))\n",
    "      return self.enc_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fe73412-393c-4672-be20-cd5b779aafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "  def __init__(self,att_units):\n",
    "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "    super().__init__()\n",
    "\n",
    "    self.att_units = att_units\n",
    "\n",
    "    self.w1 =  tf.keras.layers.Dense( self.att_units , name = 'w1')\n",
    "    self.w2 =  tf.keras.layers.Dense( self.att_units,name = 'w2')\n",
    "    self.v =  tf.keras.layers.Dense(1,name = 'v')\n",
    "    \n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    self.decoder_hidden_state = decoder_hidden_state\n",
    "    self.encoder_output = encoder_output\n",
    "\n",
    "\n",
    "    self.decoder_hidden_state = tf.expand_dims(self.decoder_hidden_state,axis = 1)\n",
    "    score = self.v(tf.nn.tanh(\n",
    "              self.w1(self.decoder_hidden_state) + self.w2(self.encoder_output)))\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "    context_vector = attention_weights * self.encoder_output\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    return context_vector,attention_weights\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d333a822-178d-42b6-b62c-348596c51670",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units  ,att_units):\n",
    "      \n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "      super().__init__()\n",
    "      self.tar_vocab_size = tar_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units = dec_units\n",
    "      self.att_units = att_units\n",
    "      self.dec_emb = Embedding(tar_vocab_size,embedding_dim,trainable = True , name = 'dec_embb')\n",
    "      self.dec_lstm = GRU(self.dec_units, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n",
    "      self.dense   = Dense(self.tar_vocab_size, name = 'one_dec')\n",
    "      self.attention=Attention( self.att_units)\n",
    "      self.d1 = Dropout(0.3,name = 'd1')\n",
    "      self.d2 = Dropout(0.3,name = 'd2')\n",
    "      self.d3 = Dropout(0.3,name = 'd3')\n",
    "\n",
    "  @tf.function\n",
    "  def call(self,input_to_decoder, encoder_output, state_h):\n",
    "    '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    '''\n",
    "    self.input_to_decoder = input_to_decoder\n",
    "    self.encoder_output = encoder_output\n",
    "    self.state_h = state_h\n",
    "\n",
    "    #A\n",
    "    target_embedd           = self.dec_emb (self.input_to_decoder)     #(batch_size,1,embedingdim)\n",
    "    #B\n",
    "    target_embedd = self.d1(target_embedd)\n",
    "\n",
    "    context_vector,attention_weights=self.attention(self.state_h,self.encoder_output) #context vector shape = (batch_size,att_units)\n",
    "    #C\n",
    "    concated = tf.concat([  tf.expand_dims(context_vector, 1),target_embedd], -1)\n",
    "    concated = self.d2(concated)\n",
    "\n",
    "    #D\n",
    "    lstm_output, hs      = self.dec_lstm(concated, initial_state=self.state_h)\n",
    "\n",
    "    lstm_output = tf.reshape(lstm_output, (-1, lstm_output.shape[2]))\n",
    "    lstm_output = self.d3(lstm_output)\n",
    "    #E\n",
    "    op = self.dense(lstm_output)\n",
    "    #op = tf.squeeze(op,[1])\n",
    "    return op,hs,attention_weights,context_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af0b9ec-b5dd-4d6d-8ca2-f17f687d6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      super().__init__()\n",
    "      self.out_vocab_size = out_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units = dec_units\n",
    "      self.att_units = att_units\n",
    "      \n",
    "      self.onestep = OneStepDecoder(self.out_vocab_size,self.embedding_dim ,self.input_length,self.dec_units,self.att_units)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state):\n",
    "\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "\n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        # Return the tensor array\n",
    "\n",
    "        all_outputs = tf.TensorArray(tf.float32,size =input_to_decoder.shape[1],name = 'output_arrays' )\n",
    "        self.input_to_decoder = input_to_decoder\n",
    "        self.encoder_output = encoder_output\n",
    "        self.decoder_hidden_state = decoder_hidden_state\n",
    "\n",
    "        for timestep in tf.range(input_to_decoder.shape[1]):\n",
    "          op,hs,attention_weights,context_vector = self.onestep(self.input_to_decoder[:,timestep:timestep+1], self.encoder_output, self.decoder_hidden_state)\n",
    "          self.decoder_hidden_state = hs\n",
    "          all_outputs = all_outputs.write(timestep,op)\n",
    "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        return all_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "570f8fc0-d6ee-4882-9016-549a499a8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  #def __init__(self,#params):\n",
    "    #Intialize objects from encoder decoder\n",
    "  def __init__(self,out_vocab_size , embedding_size_d, input_length_d,lstm_size_d,att_units,batch_size,units):\n",
    "\n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        super().__init__()\n",
    "\n",
    "        self.units = units\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size_d = embedding_size_d\n",
    "        self.lstm_size_d = lstm_size_d\n",
    "        self.input_length_d = input_length_d\n",
    "        self.batch_size = batch_size\n",
    "        self.att_units = att_units\n",
    "\n",
    "        self.encoder = Encoder(self.units)\n",
    "        print(\"OUT_VOCAB_SIZE = \",out_vocab_size, embedding_size_d,input_length_d,lstm_size_d,att_units)\n",
    "\n",
    "        self.decoder = Decoder(out_vocab_size , embedding_size_d, input_length_d,lstm_size_d,att_units )\n",
    "        #self.dense   = TimeDistributed(Dense(self.out_vocab_size, activation='softmax'))\n",
    "        self.dense   = Dense(self.out_vocab_size,name = 'enc_dec_dense')\n",
    "\n",
    "\n",
    "\n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    # return the decoder output\n",
    "    self.inputs,self.outputs = data[0], data[1]\n",
    "    print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
    "    self.encoder_h= self.encoder.initialize_states(self.batch_size)\n",
    "    self.encoder_output = self.encoder(self.inputs)\n",
    "    print(\"-\"*27)\n",
    "    print(\"ENCODER ==> OUTPUT SHAPE\",self.encoder_output.shape)\n",
    "    print(\"ENCODER ==> HIDDEN STATE SHAPE\",self.encoder_h.shape)\n",
    "    print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
    "    output= self.decoder(self.outputs,self.encoder_output,self.encoder_h)\n",
    "    print(\"-\"*27)\n",
    "    print(\"FINAL OUTPUT SHAPE\",output.shape)\n",
    "    print(\"=\"*50)\n",
    "    print(\"output = \", self.dense(output))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55d6f365-7f54-4da8-9b73-6351433ec1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 22:14:34.312844: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-06-25 22:14:34.312899: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: professor-Aspire-A715-42G\n",
      "2024-06-25 22:14:34.312911: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: professor-Aspire-A715-42G\n",
      "2024-06-25 22:14:34.313098: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.183.1\n",
      "2024-06-25 22:14:34.313130: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.171.4\n",
      "2024-06-25 22:14:34.313136: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 535.171.4 does not match DSO version 535.183.1 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "\n",
    "  return tf.reduce_mean(loss_)\n",
    "  #out_vocab_size , embedding_size_d, input_length_d,lstm_size_d,att_units,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "468f4f8b-492e-4e34-9913-87a3fc482c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory checkpoint: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8fc7afb-6530-49f2-8b5b-597477e6aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "checkpoint_filepath = cwd + '/' + 'checkpoint' + '/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da0025cd-3ecb-4964-a63c-9db22f035916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/professor/Downloads/fromgit/checkpoint/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "187ff952-e1f4-4bda-ba39-2d4d4f1f27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose = 1,\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fb7b66d-4e85-4932-b58f-5a2b3c4f8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98e504e1-d327-4cf5-a35c-6ab8311ce800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8,mode = 'min',verbose = 1,\n",
    "                              patience=2, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "441e783b-e713-4af0-82e2-451536917b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_VOCAB_SIZE =  1830 300 76 256 64\n"
     ]
    }
   ],
   "source": [
    "model_1 = encoder_decoder(vocab_size_imp,300,76,256,64,50,256)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model_1.compile(optimizer=optimizer,loss=loss_function, metrics = \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cafc915-842d-4562-bc81-2060e575bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(units=256)\n",
    "batch_size = 50\n",
    "\n",
    "encoder_hidden_state = Encoder.initialize_states(encoder,batch_size)\n",
    "print(encoder_hidden_state.shape)  # Output: (50, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7f40e03-d79c-4afc-97d9-95481a8c133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256)\n",
      "(50, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "attention = Attention(att_units=64)\n",
    "decoder_hidden_state = tf.random.normal((50, 256))\n",
    "encoder_output = tf.random.normal((50, 10, 256))\n",
    "context_vector, attention_weights = attention(decoder_hidden_state, encoder_output)\n",
    "print(context_vector.shape)  # Output: (50, 256)\n",
    "print(attention_weights.shape)  # Output: (50, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beb318e7-2b6f-44e0-808b-631df66be6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inp = np.vstack(X_train[:,4]).astype(np.float64)  # Use np.float64 for double-precision floats\n",
    "test_inp = np.vstack(X_test[:,4]).astype(np.float32)  # Use np.float32 for single-precision floats (if memory efficiency is a concern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87e60deb-dac1-47a6-b7cd-3b543bdb0aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 2.1220 - accuracy: 0.0234\n",
      "Epoch 1: val_loss improved from 2.20909 to 2.18705, saving model to /home/professor/Downloads/fromgit/checkpoint/\n",
      "==================== ENCODER ====================\n",
      "---------------------------\n",
      "ENCODER ==> OUTPUT SHAPE (None, 256)\n",
      "ENCODER ==> HIDDEN STATE SHAPE (50, 256)\n",
      "==================== DECODER ====================\n",
      "---------------------------\n",
      "FINAL OUTPUT SHAPE (50, 76, 1830)\n",
      "==================================================\n",
      "output =  Tensor(\"encoder_decoder/enc_dec_dense/BiasAdd:0\", shape=(50, 76, 1830), dtype=float32)\n",
      "==================== ENCODER ====================\n",
      "---------------------------\n",
      "ENCODER ==> OUTPUT SHAPE (None, 256)\n",
      "ENCODER ==> HIDDEN STATE SHAPE (50, 256)\n",
      "==================== DECODER ====================\n",
      "---------------------------\n",
      "FINAL OUTPUT SHAPE (None, 76, 1830)\n",
      "==================================================\n",
      "output =  Tensor(\"enc_dec_dense/StatefulPartitionedCall:0\", shape=(None, 76, 1830), dtype=float32)\n",
      "==================== ENCODER ====================\n",
      "---------------------------\n",
      "ENCODER ==> OUTPUT SHAPE (None, 256)\n",
      "ENCODER ==> HIDDEN STATE SHAPE (50, 256)\n",
      "==================== DECODER ====================\n",
      "---------------------------\n",
      "FINAL OUTPUT SHAPE (None, 76, 1830)\n",
      "==================================================\n",
      "output =  Tensor(\"enc_dec_dense/StatefulPartitionedCall:0\", shape=(None, 76, 1830), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/professor/Downloads/fromgit/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/professor/Downloads/fromgit/checkpoint/assets\n",
      "WARNING:absl:<__main__.Attention object at 0x74919f36bfa0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 44s 837ms/step - loss: 2.1220 - accuracy: 0.0234 - val_loss: 2.1870 - val_accuracy: 0.0257 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7491b8b92650>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit([train_inp,dec_inp ],dec_op ,validation_data= ([test_inp, dec_inp_cv],dec_op_cv),batch_size= 50,epochs  = 1,callbacks=[reduce_lr,model_checkpoint_callback] , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec0ec7be-911c-4fb7-99bf-d138811de862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 21:19:27.927445: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /home/professor/Downloads/fromgit/checkpoint/: FAILED_PRECONDITION: /home/professor/Downloads/fromgit/checkpoint; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x77dea026b010>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_1.load_weights(checkpoint_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd8653fe-8c2a-46bf-9ff6-f910cfccbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/\n",
    "#https://github.com/vysakh10/Medical-Report-Generation-using-Deep-Learning/blob/master/Attention_Onestep_Mod.ipynb\n",
    "def beam(sentence):\n",
    "  \"\"\" Thi function predicts the sentence using beam search \"\"\"\n",
    "\n",
    "  initial_state=model_1.layers[0].initialize_states(1)\n",
    "  encoder_output= model_1.layers[0](sentence)\n",
    "  result = ''\n",
    "\n",
    "  sequences = [['<start>' ,initial_state, 0]]\n",
    "\n",
    "  decoder_hidden_state = initial_state\n",
    "\n",
    "  #cur_vec = np.ones((1, 1)) * imp2['<start>']\n",
    "  #cur_vec = np.array([[1]])\n",
    "  finished_seq = []\n",
    "  beam_width = 3\n",
    "\n",
    "  for i in range(76):\n",
    "    all_candidates = []\n",
    "    new_seq = []\n",
    "    for s in sequences:\n",
    "\n",
    "      cur_vec = np.reshape(imp2[s[0].split(\" \")[-1]],(1,1))\n",
    "      decoder_hidden_state = s[1]\n",
    "      op,hs,attention_weights,context_vector = model_1.layers[1].onestep(cur_vec, encoder_output, decoder_hidden_state)\n",
    "      op = tf.nn.softmax(op)\n",
    "      top3 = np.argsort(op).flatten()[-beam_width:]\n",
    "      for t in top3:\n",
    "\n",
    "         candidates = [s[0] + ' '+ imp1[t], hs,s[2]-np.log(np.array(op).flatten()[t])]\n",
    "         all_candidates.append(candidates)\n",
    "    sequences = sorted(all_candidates, key = lambda l: l[2])[:beam_width]\n",
    "\n",
    "    count = 0\n",
    "    for s1 in sequences:\n",
    "      if s1[0].split(\" \")[-1] == '<end>':\n",
    "\n",
    "\n",
    "        s1[2] = s1[2]/len(s1[0])   # normalized\n",
    "        finished_seq.append([s1[0], s1[1],s1[2]])\n",
    "        count+=1\n",
    "      else:\n",
    "\n",
    "        new_seq.append([s1[0], s1[1],s1[2]])\n",
    "\n",
    "    beam_width -= count\n",
    "    sequences = new_seq\n",
    "    if not sequences:\n",
    "      break\n",
    "    else:\n",
    "      continue\n",
    "\n",
    "  if len(finished_seq) >0:\n",
    "    sequences = finished_seq[-1]\n",
    "    return sequences[0]\n",
    "  else:\n",
    "    return new_seq[-1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04207592-f7ab-48c8-bfca-7d349b097fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence is :  <start> the heart is normal in size and contour. there is no mediastinal widening. the lungs are clear bilaterally. no large pleural effusion or pneumothora. fractures of the posterior left th, th, and th ribs, age-indeterminate.\n",
      "Predicted Sentence is :  <start> the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the is\n"
     ]
    }
   ],
   "source": [
    "num = 16 #random test sample\n",
    "im_o = np.vstack(X_test[:,4][num]).astype(float)\n",
    "tex_o = X_test[:,6][num]\n",
    "\n",
    "print(\"Original Sentence is : \" , tex_o)\n",
    "print(\"Predicted Sentence is : \",beam(im_o))\n",
    "# img = cv2.imread(X_test[:,1][num], cv2.IMREAD_UNCHANGED)\n",
    "# cv2_imshow(img)\n",
    "# img = cv2.imread(X_test[:,2][num], cv2.IMREAD_UNCHANGED)\n",
    "# cv2_imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d44888f2-91fd-4160-9b53-30663816ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu1 score is :  0.32272852431776494\n",
      "Bleu2 score is :  0.16857199334071807\n",
      "Bleu3 score is :  0.0933629868126091\n",
      "Bleu4 score is :  0.043901071057910905\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "#https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "b1 = 0\n",
    "b2 = 0\n",
    "b3 = 0\n",
    "b4 = 0\n",
    "\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "  im_o = np.vstack(X_test[:,4][i]).astype(float)\n",
    "  pred = beam(im_o)\n",
    "  org= X_test[:,5][i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  b1 =  b1 + bleu.sentence_bleu([org.split()], pred.split() ,weights=(1, 0, 0, 0))\n",
    "  b2 =  b2 + bleu.sentence_bleu([org.split()], pred.split(),weights=(0.5, 0.5, 0, 0))\n",
    "  b3 =  b3 + bleu.sentence_bleu([org.split()], pred.split() ,weights=(0.33, 0.33, 0.33, 0))\n",
    "  b4 =  b4 + bleu.sentence_bleu([org.split()], pred.split() ,weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Bleu1 score is : \",b1/X_test.shape[0])\n",
    "print(\"Bleu2 score is : \",b2/X_test.shape[0])\n",
    "print(\"Bleu3 score is : \",b3/X_test.shape[0])\n",
    "print(\"Bleu4 score is : \",b4/X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ed7cf90-71ac-414b-bb99-f0996d0a4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Number: 0\n",
      "Sample Number: 100\n",
      "Sample Number: 200\n",
      "Sample Number: 300\n",
      "Sample Number: 400\n",
      "Sample Number: 500\n",
      "Sample Number: 600\n"
     ]
    }
   ],
   "source": [
    "c = set()\n",
    "for num in range(650):\n",
    "    im_o = np.vstack(X_train[:, 4][num]).astype(float)\n",
    "    tex_o = X_test[:, 6][num]\n",
    "    if(num%100 == 0):\n",
    "      print(\"Sample Number:\", num)\n",
    "    # print(\"Sample Number:\", num)\n",
    "    # print(\"Original Sentence is:\", tex_o)\n",
    "    # print(\"Predicted Sentence is:\", beam(im_o))\n",
    "    # print(\"The X-Rays are:\")\n",
    "\n",
    "    # img1 = cv2.imread(X_test[:, 1][num], cv2.IMREAD_UNCHANGED)\n",
    "    # img2 = cv2.imread(X_test[:, 2][num], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    c.add(beam(im_o))\n",
    "    # print(count)\n",
    "    # cv2_imshow(img1)\n",
    "    # cv2_imshow(img2)\n",
    "    # print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3ba30-f3d0-410d-bee2-abba92645b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7f3a5-36eb-457f-a35f-433be20edd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126a92c-5556-4fc3-9089-f082f5c266a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806978b-7430-4fd0-9ece-0b550c4ca10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511bc4f-3bc8-4012-bbe2-737e536f24c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df1403-15df-4489-930c-ab8203fe0ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da541a-5b98-49c1-bbbb-a32f773119d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ff5ef-fd02-48c4-a6c5-c4b1f0faf36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e004913-a7aa-4e1d-ac10-4e013ea192aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b47497-0ba9-4500-9932-bc48ba6699dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68948c2-897c-4df5-8e2f-5c282641c86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32524f-a6af-4c0f-b856-cb6dafb2823b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8781c8-349f-405c-b13c-fe0db492f8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f133ef4-5664-4113-90ad-d7656bbdc876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2632f-ca95-4259-87db-5118bb206a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067af2e-6107-4c27-ab2b-6d53adec94fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926391b-ec2d-4abf-9de2-7b6e2ad8d986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0c221-e820-4ed6-b798-24a883b25b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6e54b-01d4-4c36-a6b8-e6c9ed6b5ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341ae67-1001-4d86-b7b7-cd49efe7ce5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17f7ed-c975-4020-8e5c-a9ef0764caf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe959a78-a339-4d87-b811-601b7bee18f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643f6c8-e5da-4550-a7d8-de3bd69bf8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe88351-62cf-4876-82df-3634ab24b534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b699e-1b1a-4fe9-b447-0f4a5c31b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2526d7d1-87f4-4d95-9d1a-fb02be790b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OOV': 1,\n",
       " 'the': 2,\n",
       " 'no': 3,\n",
       " 'is': 4,\n",
       " 'are': 5,\n",
       " '<start>': 6,\n",
       " '<end>': 7,\n",
       " 'and': 8,\n",
       " 'pleural': 9,\n",
       " 'of': 10,\n",
       " 'or': 11,\n",
       " 'there': 12,\n",
       " 'normal': 13,\n",
       " 'heart': 14,\n",
       " 'lungs': 15,\n",
       " 'focal': 16,\n",
       " 'size': 17,\n",
       " 'within': 18,\n",
       " 'in': 19,\n",
       " 'pneumothora': 20,\n",
       " 'normal.': 21,\n",
       " 'pulmonary': 22,\n",
       " 'effusion': 23,\n",
       " 'pneumothora.': 24,\n",
       " 'effusion.': 25,\n",
       " 'limits.': 26,\n",
       " 'right': 27,\n",
       " 'silhouette': 28,\n",
       " 'mediastinal': 29,\n",
       " 'clear.': 30,\n",
       " 'airspace': 31,\n",
       " 'cardiomediastinal': 32,\n",
       " 'left': 33,\n",
       " 'clear': 34,\n",
       " 'acute': 35,\n",
       " 'consolidation': 36,\n",
       " 'lung': 37,\n",
       " 'with': 38,\n",
       " 'structures': 39,\n",
       " 'thoracic': 40,\n",
       " 'mediastinum': 41,\n",
       " 'changes': 42,\n",
       " 'unremarkable.': 43,\n",
       " 'a': 44,\n",
       " 'bony': 45,\n",
       " 'stable': 46,\n",
       " 'degenerative': 47,\n",
       " 'mild': 48,\n",
       " 'spine.': 49,\n",
       " 'without': 50,\n",
       " 'large': 51,\n",
       " 'appear': 52,\n",
       " 'contours': 53,\n",
       " 'consolidation.': 54,\n",
       " 'osseous': 55,\n",
       " 'cardiac': 56,\n",
       " 'limits': 57,\n",
       " 'size.': 58,\n",
       " '.': 59,\n",
       " 'calcified': 60,\n",
       " 'evidence': 61,\n",
       " 'for': 62,\n",
       " 'disease.': 63,\n",
       " 'intact.': 64,\n",
       " 'vascularity': 65,\n",
       " 'to': 66,\n",
       " 'visualized': 67,\n",
       " 'upper': 68,\n",
       " 'abnormality.': 69,\n",
       " 'opacity': 70,\n",
       " 'seen.': 71,\n",
       " 'lateral': 72,\n",
       " 'contour.': 73,\n",
       " 'vasculature': 74,\n",
       " 'lower': 75,\n",
       " 'disease': 76,\n",
       " 'opacities': 77,\n",
       " 'contour': 78,\n",
       " 'identified.': 79,\n",
       " 'air': 80,\n",
       " 'effusions': 81,\n",
       " 'chest': 82,\n",
       " 'bilaterally.': 83,\n",
       " 'grossly': 84,\n",
       " 'on': 85,\n",
       " 'free': 86,\n",
       " 'prior': 87,\n",
       " 'noted.': 88,\n",
       " 'lobe': 89,\n",
       " 'low': 90,\n",
       " 'bilateral': 91,\n",
       " 'effusions.': 92,\n",
       " 'aorta.': 93,\n",
       " 'space': 94,\n",
       " 'both': 95,\n",
       " 'spine': 96,\n",
       " 'small': 97,\n",
       " 'visible': 98,\n",
       " 'thora': 99,\n",
       " 'volumes': 100,\n",
       " 'hilar': 101,\n",
       " 'present': 102,\n",
       " 'rib': 103,\n",
       " 'soft': 104,\n",
       " 'pneumothoraces.': 105,\n",
       " 'epanded.': 106,\n",
       " 'interstitial': 107,\n",
       " 'silhouette.': 108,\n",
       " 'nodules': 109,\n",
       " 'contours.': 110,\n",
       " 'negative': 111,\n",
       " 'findings.': 112,\n",
       " 'aorta': 113,\n",
       " 'vascular': 114,\n",
       " 'seen': 115,\n",
       " 'areas': 116,\n",
       " 'mildly': 117,\n",
       " 'enlarged.': 118,\n",
       " 'definite': 119,\n",
       " 'granuloma': 120,\n",
       " 'aortic': 121,\n",
       " 'otherwise': 122,\n",
       " 'edema.': 123,\n",
       " 'appearance.': 124,\n",
       " 'atelectasis.': 125,\n",
       " 'stable.': 126,\n",
       " 'infiltrate': 127,\n",
       " 'which': 128,\n",
       " 'from': 129,\n",
       " 'at': 130,\n",
       " 'suspicious': 131,\n",
       " 'opacities.': 132,\n",
       " 'abnormalities.': 133,\n",
       " 'granulomatous': 134,\n",
       " 'costophrenic': 135,\n",
       " 'infiltrate.': 136,\n",
       " 'frontal': 137,\n",
       " 'unchanged': 138,\n",
       " 'atelectasis': 139,\n",
       " 'not': 140,\n",
       " 'lobe.': 141,\n",
       " 'central': 142,\n",
       " 'noted': 143,\n",
       " 'masses.': 144,\n",
       " 'volumes.': 145,\n",
       " 'suggest': 146,\n",
       " 'atherosclerotic': 147,\n",
       " 'appears': 148,\n",
       " 'base': 149,\n",
       " 'increased': 150,\n",
       " 'minimal': 151,\n",
       " 'cardiomegaly.': 152,\n",
       " 'chronic': 153,\n",
       " 'lungs.': 154,\n",
       " 'specifically': 155,\n",
       " 'consistent': 156,\n",
       " 'tip': 157,\n",
       " 'overlying': 158,\n",
       " 'tissues': 159,\n",
       " 'have': 160,\n",
       " 'may': 161,\n",
       " 'scarring': 162,\n",
       " 'be': 163,\n",
       " 'has': 164,\n",
       " 'patient': 165,\n",
       " 'spaces': 166,\n",
       " 'an': 167,\n",
       " 'interval.': 168,\n",
       " 'findings': 169,\n",
       " 'again': 170,\n",
       " 'this': 171,\n",
       " 'opacity.': 172,\n",
       " 'sternotomy': 173,\n",
       " 'anterior': 174,\n",
       " 'surgical': 175,\n",
       " 'clips': 176,\n",
       " 'alveolar': 177,\n",
       " 'lymph': 178,\n",
       " 'eamination': 179,\n",
       " 'pneumonia.': 180,\n",
       " 'skeletal': 181,\n",
       " 'basilar': 182,\n",
       " 'well': 183,\n",
       " 'show': 184,\n",
       " 'cardio': 185,\n",
       " 'interval': 186,\n",
       " 'prominent': 187,\n",
       " 'posterior': 188,\n",
       " 'views': 189,\n",
       " 'scattered': 190,\n",
       " 'chest.': 191,\n",
       " 'present.': 192,\n",
       " 'trachea': 193,\n",
       " 'inflated': 194,\n",
       " 'th': 195,\n",
       " 'density': 196,\n",
       " 'bone': 197,\n",
       " 'scarring.': 198,\n",
       " 'displaced': 199,\n",
       " 'unchanged.': 200,\n",
       " 'edema': 201,\n",
       " 'moderate': 202,\n",
       " 'tortuous': 203,\n",
       " 'infiltrates.': 204,\n",
       " 'sided': 205,\n",
       " 'patchy': 206,\n",
       " 'bibasilar': 207,\n",
       " 'bronchovascular': 208,\n",
       " 'base.': 209,\n",
       " 'midline.': 210,\n",
       " 'markings': 211,\n",
       " 'normally': 212,\n",
       " 'calcifications': 213,\n",
       " 'typical': 214,\n",
       " 'represent': 215,\n",
       " 'previous': 216,\n",
       " 'streaky': 217,\n",
       " 'blunting': 218,\n",
       " 'over': 219,\n",
       " 'silhouettes': 220,\n",
       " 'view': 221,\n",
       " 'spondylosis.': 222,\n",
       " 'fracture': 223,\n",
       " 'nodule': 224,\n",
       " 'granuloma.': 225,\n",
       " 'appearance': 226,\n",
       " 'view.': 227,\n",
       " 'adenopathy': 228,\n",
       " 'mid': 229,\n",
       " 'change': 230,\n",
       " 'nodular': 231,\n",
       " 'hemidiaphragm.': 232,\n",
       " 'but': 233,\n",
       " 'diaphragm.': 234,\n",
       " 'hyperepanded': 235,\n",
       " 'pneumonia': 236,\n",
       " 'cm': 237,\n",
       " 'cardiomegaly': 238,\n",
       " 'vertebral': 239,\n",
       " 'tortuosity': 240,\n",
       " 'bilaterally': 241,\n",
       " 'catheter': 242,\n",
       " 'fractures': 243,\n",
       " 'tissue': 244,\n",
       " 'old': 245,\n",
       " 'limited': 246,\n",
       " 'been': 247,\n",
       " 'consolidations.': 248,\n",
       " 'compatible': 249,\n",
       " 't': 250,\n",
       " 'multiple': 251,\n",
       " 'obtained.': 252,\n",
       " 'hemidiaphragm': 253,\n",
       " 'unremarkable': 254,\n",
       " 'identified': 255,\n",
       " 'granulomas.': 256,\n",
       " 'deformity': 257,\n",
       " 'compared': 258,\n",
       " 'tortuous.': 259,\n",
       " 'as': 260,\n",
       " 'vascularity.': 261,\n",
       " 'enlarged': 262,\n",
       " 'under': 263,\n",
       " 'fractures.': 264,\n",
       " 'mm': 265,\n",
       " 'abnormality': 266,\n",
       " 'pa': 267,\n",
       " 'than': 268,\n",
       " 'subsegmental': 269,\n",
       " 'infiltrates': 270,\n",
       " 'significant': 271,\n",
       " 'hyperinflated': 272,\n",
       " 'calcification': 273,\n",
       " 'intraperitoneal': 274,\n",
       " 'radiographs': 275,\n",
       " 'was': 276,\n",
       " 'elevation': 277,\n",
       " 'diffuse': 278,\n",
       " 'midlung': 279,\n",
       " 'hyperepanded.': 280,\n",
       " 'prominence': 281,\n",
       " 'body': 282,\n",
       " 'also': 283,\n",
       " 'consists': 284,\n",
       " 'intact': 285,\n",
       " 'middle': 286,\n",
       " 'projecting': 287,\n",
       " 'emphysema.': 288,\n",
       " 'demonstrate': 289,\n",
       " 'crowding.': 290,\n",
       " 'hiatal': 291,\n",
       " 'thoracolumbar': 292,\n",
       " 'changes.': 293,\n",
       " 'granulomas': 294,\n",
       " 'throughout': 295,\n",
       " 'apical': 296,\n",
       " 'fracture.': 297,\n",
       " 'age.': 298,\n",
       " 'postsurgical': 299,\n",
       " 'distal': 300,\n",
       " 'abdomen': 301,\n",
       " 'perihilar': 302,\n",
       " 'heart.': 303,\n",
       " 'slightly': 304,\n",
       " 'any': 305,\n",
       " 'fluid.': 306,\n",
       " 'emphysematous': 307,\n",
       " 'appearing': 308,\n",
       " 'lung.': 309,\n",
       " 'borderline': 310,\n",
       " 'remains': 311,\n",
       " 'low.': 312,\n",
       " 'reveal': 313,\n",
       " 'area': 314,\n",
       " 'remain': 315,\n",
       " 'flattening': 316,\n",
       " 'versus': 317,\n",
       " 'multilevel': 318,\n",
       " 'superior': 319,\n",
       " 'arthritic': 320,\n",
       " 'some': 321,\n",
       " 'crowding': 322,\n",
       " 'ap': 323,\n",
       " 'were': 324,\n",
       " 'most': 325,\n",
       " 'svc.': 326,\n",
       " 'study.': 327,\n",
       " 'configuration.': 328,\n",
       " 'due': 329,\n",
       " 'osteophytes.': 330,\n",
       " 'cervical': 331,\n",
       " 'aerated.': 332,\n",
       " 'evaluation': 333,\n",
       " 'along': 334,\n",
       " 'eam.': 335,\n",
       " 'secondary': 336,\n",
       " 'similar': 337,\n",
       " 'junction.': 338,\n",
       " 'bases': 339,\n",
       " 'hernia.': 340,\n",
       " 'greater': 341,\n",
       " 'near': 342,\n",
       " 'hypoinflated': 343,\n",
       " 'midthoracic': 344,\n",
       " 'eam': 345,\n",
       " 'endplate': 346,\n",
       " 'mediastinum.': 347,\n",
       " 'leads': 348,\n",
       " 'densities': 349,\n",
       " 'epanded': 350,\n",
       " 'biapical': 351,\n",
       " 'widening.': 352,\n",
       " 'images.': 353,\n",
       " 'venous': 354,\n",
       " 'retrocardiac': 355,\n",
       " 'significantly': 356,\n",
       " 'descending': 357,\n",
       " 'thickening': 358,\n",
       " 'disc': 359,\n",
       " 'enlargement': 360,\n",
       " 'could': 361,\n",
       " 'process.': 362,\n",
       " 'representing': 363,\n",
       " 'left.': 364,\n",
       " 'eamination.': 365,\n",
       " 'eventration': 366,\n",
       " 'fluid': 367,\n",
       " 'configuration': 368,\n",
       " 'represents': 369,\n",
       " 'approimately': 370,\n",
       " 'rib.': 371,\n",
       " 'severe': 372,\n",
       " 'nodule.': 373,\n",
       " 'demonstrated.': 374,\n",
       " 'persistent': 375,\n",
       " 'mass': 376,\n",
       " 'study': 377,\n",
       " 'partially': 378,\n",
       " 'ape': 379,\n",
       " 'humeral': 380,\n",
       " 'possibly': 381,\n",
       " 'abdomen.': 382,\n",
       " 'medial': 383,\n",
       " 'clavicle': 384,\n",
       " 'by': 385,\n",
       " 'region': 386,\n",
       " 'lucency': 387,\n",
       " 'demonstrated': 388,\n",
       " 'suggesting': 389,\n",
       " 'measuring': 390,\n",
       " 'engorgement': 391,\n",
       " 'detroscoliosis': 392,\n",
       " 'lumbar': 393,\n",
       " 'top': 394,\n",
       " 'overall': 395,\n",
       " 'vasculature.': 396,\n",
       " 'midlung.': 397,\n",
       " 'reveals': 398,\n",
       " 'airways': 399,\n",
       " 'line': 400,\n",
       " 'congestion.': 401,\n",
       " 'vague': 402,\n",
       " 'convincing': 403,\n",
       " 'masses': 404,\n",
       " 'dense': 405,\n",
       " 'joint': 406,\n",
       " 'midline': 407,\n",
       " 'post': 408,\n",
       " 'curvature': 409,\n",
       " 'bases.': 410,\n",
       " 'scoliosis': 411,\n",
       " 'calcifications.': 412,\n",
       " 'suggestive': 413,\n",
       " 'ape.': 414,\n",
       " 'cabg.': 415,\n",
       " 'however': 416,\n",
       " 'healed': 417,\n",
       " 'through': 418,\n",
       " 'parenchymal': 419,\n",
       " 'since': 420,\n",
       " 'quadrant.': 421,\n",
       " 'diaphragm': 422,\n",
       " 'breast': 423,\n",
       " 'calcification.': 424,\n",
       " 'these': 425,\n",
       " 'related': 426,\n",
       " 'hyperinflation': 427,\n",
       " 'ribs': 428,\n",
       " 'flattened': 429,\n",
       " 'lobes.': 430,\n",
       " 'redemonstration': 431,\n",
       " 'prior.': 432,\n",
       " 'probable': 433,\n",
       " 'comparison': 434,\n",
       " 'hyperepansion': 435,\n",
       " 'osteophytes': 436,\n",
       " 'projection.': 437,\n",
       " 'several': 438,\n",
       " 'associated': 439,\n",
       " 'loss': 440,\n",
       " 'markings.': 441,\n",
       " 'diaphragms': 442,\n",
       " 'ectasia': 443,\n",
       " 'change.': 444,\n",
       " 'segment': 445,\n",
       " 'marked': 446,\n",
       " 'large.': 447,\n",
       " 'given': 448,\n",
       " 'one': 449,\n",
       " 'paratracheal': 450,\n",
       " 'eternal': 451,\n",
       " 'right.': 452,\n",
       " 'deformities': 453,\n",
       " 'elevated': 454,\n",
       " 'widening': 455,\n",
       " 'calcified.': 456,\n",
       " 'wall': 457,\n",
       " 'amount': 458,\n",
       " 'cholecystectomy': 459,\n",
       " 'removal': 460,\n",
       " 'consolidations': 461,\n",
       " 'unfolding': 462,\n",
       " 'sequela': 463,\n",
       " 'level': 464,\n",
       " 'ribs.': 465,\n",
       " 'volume': 466,\n",
       " 'atrium.': 467,\n",
       " 'note': 468,\n",
       " 'subclavian': 469,\n",
       " 'decreased': 470,\n",
       " 'moderately': 471,\n",
       " 'atrial': 472,\n",
       " 'position.': 473,\n",
       " 'hernia': 474,\n",
       " 'rounded': 475,\n",
       " 'rotated': 476,\n",
       " 'eaggerated': 477,\n",
       " 'thickening.': 478,\n",
       " 'inferior': 479,\n",
       " 'obstructive': 480,\n",
       " 'region.': 481,\n",
       " 'kyphosis.': 482,\n",
       " 'tube': 483,\n",
       " 'picc': 484,\n",
       " 'bodies': 485,\n",
       " 'previously': 486,\n",
       " 'developed': 487,\n",
       " 'elevated.': 488,\n",
       " 'etensive': 489,\n",
       " 'shoulder': 490,\n",
       " 'monitor': 491,\n",
       " 'postoperative': 492,\n",
       " 'dual': 493,\n",
       " 'hypoinflated.': 494,\n",
       " 'clips.': 495,\n",
       " 'active': 496,\n",
       " 'that': 497,\n",
       " 'body.': 498,\n",
       " 'age': 499,\n",
       " 'superimposed': 500,\n",
       " 'status': 501,\n",
       " 'sequelae': 502,\n",
       " 'artery': 503,\n",
       " 'calcific': 504,\n",
       " 'tortuosity.': 505,\n",
       " 'fusion': 506,\n",
       " 'sulcus': 507,\n",
       " 'involving': 508,\n",
       " 'aspect': 509,\n",
       " 'improved': 510,\n",
       " 'aeration': 511,\n",
       " 'two': 512,\n",
       " 'air.': 513,\n",
       " 'projection': 514,\n",
       " 'reflect': 515,\n",
       " 'cavitary': 516,\n",
       " 'peripheral': 517,\n",
       " 'atrium': 518,\n",
       " 'injury.': 519,\n",
       " 'remote': 520,\n",
       " 'osteophyte': 521,\n",
       " 'suggests': 522,\n",
       " 'round': 523,\n",
       " 'cabg': 524,\n",
       " 'irregularity': 525,\n",
       " 'first': 526,\n",
       " 'discrete': 527,\n",
       " 'foreign': 528,\n",
       " 'obscuration': 529,\n",
       " 'irregular': 530,\n",
       " 'somewhat': 531,\n",
       " 'noncalcified': 532,\n",
       " 'atherosclerotic.': 533,\n",
       " 'projects': 534,\n",
       " 'ventricle.': 535,\n",
       " 'pericardial': 536,\n",
       " 'device': 537,\n",
       " 'numerous': 538,\n",
       " 'epicardial': 539,\n",
       " 'underlying': 540,\n",
       " 'residual': 541,\n",
       " 'kyphosis': 542,\n",
       " 'wedge': 543,\n",
       " 'pectus': 544,\n",
       " 'deformity.': 545,\n",
       " 'sized': 546,\n",
       " 'technical': 547,\n",
       " 'factors': 548,\n",
       " 'quadrant': 549,\n",
       " 'congestion': 550,\n",
       " 'enlargement.': 551,\n",
       " 'technique.': 552,\n",
       " 'sternotomy.': 553,\n",
       " 'more': 554,\n",
       " 'fissure.': 555,\n",
       " 'overlies': 556,\n",
       " 'projected': 557,\n",
       " 'ectatic': 558,\n",
       " 'formation': 559,\n",
       " 'defined': 560,\n",
       " 'scar': 561,\n",
       " 'lobar': 562,\n",
       " 'valve': 563,\n",
       " 'nipple': 564,\n",
       " 'position': 565,\n",
       " 'cholecystectomy.': 566,\n",
       " 'proimal': 567,\n",
       " 'retrosternal': 568,\n",
       " 'bowel': 569,\n",
       " 'partial': 570,\n",
       " 'abnormalities': 571,\n",
       " 'infection.': 572,\n",
       " 'contrast': 573,\n",
       " 'abdominal': 574,\n",
       " 'ct': 575,\n",
       " 'head': 576,\n",
       " 'its': 577,\n",
       " 'cavoatrial': 578,\n",
       " 'cannot': 579,\n",
       " 'ecluded.': 580,\n",
       " 'fat': 581,\n",
       " 'atherosclerosis': 582,\n",
       " 'accentuated': 583,\n",
       " 'catheter.': 584,\n",
       " 'internal': 585,\n",
       " 'jugular': 586,\n",
       " 'hemidiaphragms.': 587,\n",
       " 'subdiaphragmatic': 588,\n",
       " 'adjacent': 589,\n",
       " 'zone.': 590,\n",
       " 'lingula.': 591,\n",
       " 'shoulder.': 592,\n",
       " 'few': 593,\n",
       " 'lesion': 594,\n",
       " 'dislocation.': 595,\n",
       " 'coronary': 596,\n",
       " 'diaphragms.': 597,\n",
       " 'osseus': 598,\n",
       " 'artifact.': 599,\n",
       " 'spinal': 600,\n",
       " 'abnormal': 601,\n",
       " 'opacification.': 602,\n",
       " 'hip': 603,\n",
       " 'destructive': 604,\n",
       " 'ill': 605,\n",
       " 'levoscoliosis': 606,\n",
       " 'diameter': 607,\n",
       " 'ij': 608,\n",
       " 'measures': 609,\n",
       " 'relative': 610,\n",
       " 'remainder': 611,\n",
       " 'habitus.': 612,\n",
       " 'nodules.': 613,\n",
       " 'bodies.': 614,\n",
       " 'possible': 615,\n",
       " 'epected': 616,\n",
       " 'hyperlucent': 617,\n",
       " 'apparent': 618,\n",
       " 'visualized.': 619,\n",
       " 'tracheostomy': 620,\n",
       " 'hilum.': 621,\n",
       " 'osteopenia': 622,\n",
       " 'hilum': 623,\n",
       " 'symmetric': 624,\n",
       " 'it': 625,\n",
       " 'wedging': 626,\n",
       " 'pneumoperitoneum.': 627,\n",
       " 'placement': 628,\n",
       " 'correlate': 629,\n",
       " 'ascending': 630,\n",
       " 'generator': 631,\n",
       " 'terminating': 632,\n",
       " 'fibrosis.': 633,\n",
       " 'blunted.': 634,\n",
       " 'predominantly': 635,\n",
       " 'overlie': 636,\n",
       " 'lumen': 637,\n",
       " 'deformities.': 638,\n",
       " 'lordotic': 639,\n",
       " 'neck': 640,\n",
       " 'ct.': 641,\n",
       " 'apices.': 642,\n",
       " 'outside': 643,\n",
       " 'shows': 644,\n",
       " 'development': 645,\n",
       " 'knee': 646,\n",
       " 'known': 647,\n",
       " 'demonstrates': 648,\n",
       " 'subtle': 649,\n",
       " 'would': 650,\n",
       " 'femoral': 651,\n",
       " 'other': 652,\n",
       " 'hyperinflation.': 653,\n",
       " 'zone': 654,\n",
       " 'acromioclavicular': 655,\n",
       " 'posttraumatic': 656,\n",
       " 'lingula': 657,\n",
       " 'coarse': 658,\n",
       " 'diameter.': 659,\n",
       " 'detro': 660,\n",
       " 'single': 661,\n",
       " 'pacemaker': 662,\n",
       " 'ectatic.': 663,\n",
       " 'asymmetric': 664,\n",
       " 'stomach': 665,\n",
       " 'rightward': 666,\n",
       " 'basal': 667,\n",
       " 'cortical': 668,\n",
       " 'history': 669,\n",
       " 'lingular': 670,\n",
       " 'lesions': 671,\n",
       " 'concerning': 672,\n",
       " 'caliber.': 673,\n",
       " 'further': 674,\n",
       " 'aillary': 675,\n",
       " 'curvilinear': 676,\n",
       " 'indeterminate': 677,\n",
       " 'blunted': 678,\n",
       " 'loops': 679,\n",
       " 'scar.': 680,\n",
       " 'causing': 681,\n",
       " 'cardiopulmonary': 682,\n",
       " 'bandlike': 683,\n",
       " 'tissues.': 684,\n",
       " 'injury': 685,\n",
       " 'atherosclerosis.': 686,\n",
       " 'collections.': 687,\n",
       " 'sutures': 688,\n",
       " 'bypass': 689,\n",
       " 'cystic': 690,\n",
       " 'irregularities': 691,\n",
       " 'comparison.': 692,\n",
       " 'clavicle.': 693,\n",
       " 'sulci': 694,\n",
       " 'including': 695,\n",
       " 'appreciated': 696,\n",
       " 'subcutaneous': 697,\n",
       " 'caval': 698,\n",
       " 'relatively': 699,\n",
       " 'differences': 700,\n",
       " 'early': 701,\n",
       " 'fiation': 702,\n",
       " 'cm.': 703,\n",
       " 'appreciated.': 704,\n",
       " 'increase': 705,\n",
       " 'hemidiaphragms': 706,\n",
       " 'transverse': 707,\n",
       " 'question': 708,\n",
       " 'scan': 709,\n",
       " 'available': 710,\n",
       " 'adenopathy.': 711,\n",
       " 'lobes': 712,\n",
       " 'pattern': 713,\n",
       " 'shaped': 714,\n",
       " 'kyphotic': 715,\n",
       " 'stimulator': 716,\n",
       " 'infrahilar': 717,\n",
       " 'azygos': 718,\n",
       " 'tips': 719,\n",
       " 'considering': 720,\n",
       " 'vein.': 721,\n",
       " 'femur': 722,\n",
       " 'images': 723,\n",
       " 'well.': 724,\n",
       " 'suture': 725,\n",
       " 'surgery.': 726,\n",
       " 'shift.': 727,\n",
       " 'obscured': 728,\n",
       " 'fibrosis': 729,\n",
       " 'between': 730,\n",
       " 'platelike': 731,\n",
       " 'joints': 732,\n",
       " 'healing': 733,\n",
       " 'better': 734,\n",
       " 'incompletely': 735,\n",
       " 'evaluated': 736,\n",
       " 'only': 737,\n",
       " 'silhouettes.': 738,\n",
       " 'evaluation.': 739,\n",
       " 'scoliosis.': 740,\n",
       " 'confluent': 741,\n",
       " 'structures.': 742,\n",
       " 'diminished': 743,\n",
       " 'consolidative': 744,\n",
       " 'ecluded': 745,\n",
       " 'sclerotic': 746,\n",
       " 'lymphadenopathy.': 747,\n",
       " 'dilated': 748,\n",
       " 'arteries.': 749,\n",
       " 'density.': 750,\n",
       " 'scoliotic': 751,\n",
       " 'portions': 752,\n",
       " 'probably': 753,\n",
       " 'artifact': 754,\n",
       " 'neck.': 755,\n",
       " 'indicate': 756,\n",
       " 'questionable': 757,\n",
       " 'wall.': 758,\n",
       " 'ailla.': 759,\n",
       " 'minimally': 760,\n",
       " 'aerated': 761,\n",
       " 'tunneled': 762,\n",
       " 'dialysis': 763,\n",
       " 'pelvis.': 764,\n",
       " 'coarsened': 765,\n",
       " 'radiograph.': 766,\n",
       " 'fat.': 767,\n",
       " 'supine': 768,\n",
       " 'indistinct': 769,\n",
       " 'breast.': 770,\n",
       " 'posteriorly': 771,\n",
       " 'stent.': 772,\n",
       " 'tuberculosis.': 773,\n",
       " 'obscures': 774,\n",
       " 'indeterminate.': 775,\n",
       " 'hyperepansion.': 776,\n",
       " 'worse': 777,\n",
       " 'obtained': 778,\n",
       " 'incidental': 779,\n",
       " 'etremity': 780,\n",
       " 'slight': 781,\n",
       " 'narrowing': 782,\n",
       " 'head.': 783,\n",
       " 'process': 784,\n",
       " 'tuberculous': 785,\n",
       " 'uncertain': 786,\n",
       " 'shadows': 787,\n",
       " 'prominence.': 788,\n",
       " 'marginal': 789,\n",
       " 'dislocations.': 790,\n",
       " 'stent': 791,\n",
       " 'material': 792,\n",
       " 'airways.': 793,\n",
       " 'mitral': 794,\n",
       " 't.': 795,\n",
       " 'diffusely': 796,\n",
       " 'rotation.': 797,\n",
       " 'technique': 798,\n",
       " 'gross': 799,\n",
       " 'detrocurvature': 800,\n",
       " 'bullae': 801,\n",
       " 'addition': 802,\n",
       " 'studies.': 803,\n",
       " 'overt': 804,\n",
       " 'ventricular': 805,\n",
       " 'glenohumeral': 806,\n",
       " 'glenoid': 807,\n",
       " 'svc': 808,\n",
       " 'pelvis': 809,\n",
       " 'above': 810,\n",
       " 'prominent.': 811,\n",
       " 'opacification': 812,\n",
       " 'tube.': 813,\n",
       " 'improvement': 814,\n",
       " 'unfolded.': 815,\n",
       " 'if': 816,\n",
       " 'fusion.': 817,\n",
       " 'node.': 818,\n",
       " 'radiographic': 819,\n",
       " 'parenchyma': 820,\n",
       " 'emphysema': 821,\n",
       " 'demineralization.': 822,\n",
       " 'performed': 823,\n",
       " 'replacement.': 824,\n",
       " 'junction': 825,\n",
       " 'thora.': 826,\n",
       " 'lobectomy.': 827,\n",
       " 'stool': 828,\n",
       " 'copd.': 829,\n",
       " 'suprahilar': 830,\n",
       " 'overlapping': 831,\n",
       " 'overlap': 832,\n",
       " 'apices': 833,\n",
       " 'obscure': 834,\n",
       " 'radiograph': 835,\n",
       " 'now': 836,\n",
       " 'trachea.': 837,\n",
       " 'eventration.': 838,\n",
       " 'humerus.': 839,\n",
       " 'bullet': 840,\n",
       " 'characteristic': 841,\n",
       " 'atelectatic': 842,\n",
       " 'collapse': 843,\n",
       " 'does': 844,\n",
       " 'resolution': 845,\n",
       " 'maintained.': 846,\n",
       " 'hemithora': 847,\n",
       " 'graft': 848,\n",
       " 'electronic': 849,\n",
       " 'advanced': 850,\n",
       " 'metastatic': 851,\n",
       " 'shadows.': 852,\n",
       " 'clinical': 853,\n",
       " 'recommended.': 854,\n",
       " 'hiatus': 855,\n",
       " 'decreased.': 856,\n",
       " 'destruction.': 857,\n",
       " 'eaggeration': 858,\n",
       " 'deep': 859,\n",
       " 'vertebroplasty': 860,\n",
       " 'unfolded': 861,\n",
       " 'non': 862,\n",
       " 'engorged.': 863,\n",
       " 'margination.': 864,\n",
       " 'accounting': 865,\n",
       " 'third': 866,\n",
       " 'shape.': 867,\n",
       " 'sided.': 868,\n",
       " 'obliquely': 869,\n",
       " 'oriented': 870,\n",
       " 'increased.': 871,\n",
       " 'space.': 872,\n",
       " 'fullness': 873,\n",
       " 'smaller': 874,\n",
       " 'dislocation': 875,\n",
       " 'ankle.': 876,\n",
       " 's': 877,\n",
       " 'airway': 878,\n",
       " 'like': 879,\n",
       " 'redemonstrated.': 880,\n",
       " 'humerus': 881,\n",
       " 'sclerosis': 882,\n",
       " 'subchondral': 883,\n",
       " 'eams.': 884,\n",
       " 'rotator': 885,\n",
       " 'mass.': 886,\n",
       " 'positional.': 887,\n",
       " 'markers.': 888,\n",
       " 'broken': 889,\n",
       " 'aicd': 890,\n",
       " 'image': 891,\n",
       " 'less': 892,\n",
       " 'knee.': 893,\n",
       " 'they': 894,\n",
       " 'radiopaque': 895,\n",
       " 'removed.': 896,\n",
       " 'fibrotic': 897,\n",
       " 'reticular': 898,\n",
       " 'lesions.': 899,\n",
       " 'procedure.': 900,\n",
       " 'margin': 901,\n",
       " 'cardiophrenic': 902,\n",
       " 'collection': 903,\n",
       " 'ventricle': 904,\n",
       " 'retraction': 905,\n",
       " 'recent': 906,\n",
       " 'prosthetic': 907,\n",
       " 'loculated': 908,\n",
       " 'b': 909,\n",
       " 'oval': 910,\n",
       " 'layering': 911,\n",
       " 'deviation': 912,\n",
       " 'below': 913,\n",
       " 'eclude': 914,\n",
       " 'tubing': 915,\n",
       " 'fissural': 916,\n",
       " 'greatest': 917,\n",
       " 'spurring': 918,\n",
       " 'fourth': 919,\n",
       " 'recess': 920,\n",
       " 'discoid': 921,\n",
       " 'consider': 922,\n",
       " 'denser': 923,\n",
       " 'pneumomediastinum.': 924,\n",
       " 'infectious': 925,\n",
       " 'thoracotomy': 926,\n",
       " 'elevation.': 927,\n",
       " 'closure': 928,\n",
       " 'regions.': 929,\n",
       " 'developing': 930,\n",
       " 'whose': 931,\n",
       " 'evaluate': 932,\n",
       " 'pleura': 933,\n",
       " 'blunting.': 934,\n",
       " 'airspace.': 935,\n",
       " 'filled': 936,\n",
       " 'colon.': 937,\n",
       " 'location': 938,\n",
       " 'chronically': 939,\n",
       " 'rotated.': 940,\n",
       " 'strandy': 941,\n",
       " 'views.': 942,\n",
       " 'fragments': 943,\n",
       " 'levels.': 944,\n",
       " 'spondylosis': 945,\n",
       " 'consolidating': 946,\n",
       " 'prosthesis': 947,\n",
       " 'evaluated.': 948,\n",
       " 'gastroesophageal': 949,\n",
       " 'epigastric': 950,\n",
       " 'flowing': 951,\n",
       " 'rectum.': 952,\n",
       " 'vasculatures': 953,\n",
       " 'vertebra.': 954,\n",
       " 'l': 955,\n",
       " 'icd': 956,\n",
       " 'distribution': 957,\n",
       " 'callus': 958,\n",
       " 'etiology': 959,\n",
       " 'concern': 960,\n",
       " 'partly': 961,\n",
       " 'alignment': 962,\n",
       " 'hyperinflated.': 963,\n",
       " 'colon': 964,\n",
       " 'aneurysm.': 965,\n",
       " 'remaining': 966,\n",
       " 'hyperlucency': 967,\n",
       " 'markedly': 968,\n",
       " 'ecavatum': 969,\n",
       " 'favored': 970,\n",
       " 'attenuation': 971,\n",
       " 'particularly': 972,\n",
       " 'limit': 973,\n",
       " 'additional': 974,\n",
       " 'lines': 975,\n",
       " 'decubitus': 976,\n",
       " 'bullous': 977,\n",
       " 'obvious': 978,\n",
       " 'markers': 979,\n",
       " 'inlet.': 980,\n",
       " 'very': 981,\n",
       " 'persistently': 982,\n",
       " 'interstitium': 983,\n",
       " 'eams': 984,\n",
       " 'confluence': 985,\n",
       " 'radiodensity': 986,\n",
       " 'rotatory': 987,\n",
       " 'testes': 988,\n",
       " 'dish.': 989,\n",
       " 'rotation': 990,\n",
       " 'film.': 991,\n",
       " 'reduced': 992,\n",
       " 'prostheses': 993,\n",
       " 'decrease': 994,\n",
       " 'displacement': 995,\n",
       " 'fragment.': 996,\n",
       " 'arthritis.': 997,\n",
       " 'tricompartmental': 998,\n",
       " 'obliteration': 999,\n",
       " 'compartment.': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l2\n",
    "import cv2 as cv\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow import concat\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM,Layer,Dropout,GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import repeat\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"done importing\")\n",
    "\n",
    "data = pd.read_pickle('/home/professor/Downloads/fromgit/processed.pkl')\n",
    "X_train, X_test = train_test_split(data.values , test_size = 0.2 )\n",
    "data.head(5)\n",
    "patient_id\timage1\timage2\tfindings\timage_features\tfindings_total\tdec_ip\tdec_op\n",
    "0\tCXR3556\t/content/png/CXR3556_IM-1741-1001-0001.png\t/content/png/CXR3556_IM-1741-1001-0002.png\tthe lungs are clear. there is no pleural effus...\t[[0.00041582860285416245, 0.001570420921780169...\t<start> the lungs are clear. there is no pleur...\t<start> the lungs are clear. there is no pleur...\tthe lungs are clear. there is no pleural effus...\n",
    "2\tCXR32\t/content/png/CXR32_IM-1511-1001.png\t/content/png/CXR32_IM-1511-4001.png\tthe heart is normal in size. the mediastinum i...\t[[0.0005354544264264405, 0.0019668142776936293...\t<start> the heart is normal in size. the media...\t<start> the heart is normal in size. the media...\tthe heart is normal in size. the mediastinum i...\n",
    "4\tCXR260\t/content/png/CXR260_IM-1090-1001.png\t/content/png/CXR260_IM-1090-2001.png\tlungs are clear bilaterally. cardiac and media...\t[[0.0002745636156760156, 0.0018877924885600805...\t<start> lungs are clear bilaterally. cardiac a...\t<start> lungs are clear bilaterally. cardiac a...\tlungs are clear bilaterally. cardiac and media...\n",
    "5\tCXR1301\t/content/png/CXR1301_IM-0198-1001.png\t/content/png/CXR1301_IM-0198-2001.png\theart size within normal limits, stable medias...\t[[0.0005874697235412896, 0.0018448150949552655...\t<start> heart size within normal limits, stabl...\t<start> heart size within normal limits, stabl...\theart size within normal limits, stable medias...\n",
    "6\tCXR1921\t/content/png/CXR1921_IM-0598-1001.png\t/content/png/CXR1921_IM-0598-2001.png\tredemonstration of moderately-inflated lungs, ...\t[[0.00029747304506599903, 0.0014215346891433, ...\t<start> redemonstration of moderately-inflated...\t<start> redemonstration of moderately-inflated...\tredemonstration of moderately-inflated lungs, ...\n",
    "\n",
    "\n",
    "t1 = Tokenizer( filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n',oov_token='OOV')\n",
    "t1.fit_on_texts(X_train[:,5])\n",
    "vocab_size_imp = len(t1.word_index) + 1\n",
    "\n",
    "dec_inp = t1.texts_to_sequences(X_train[:,6])\n",
    "\n",
    "dec_inp = pad_sequences(dec_inp, maxlen=76, padding='post')\n",
    "\n",
    "dec_inp_cv = t1.texts_to_sequences(X_test[:,6])\n",
    "\n",
    "dec_inp_cv = pad_sequences(dec_inp_cv, maxlen=76, padding='post')\n",
    "\n",
    "dec_op = t1.texts_to_sequences(X_train[:,7])\n",
    "\n",
    "dec_op = pad_sequences(dec_op, maxlen=76, padding='post')\n",
    "\n",
    "dec_op_cv = t1.texts_to_sequences(X_test[:,7])\n",
    "\n",
    "dec_op_cv = pad_sequences(dec_op_cv, maxlen=76, padding='post')\n",
    "\n",
    "\n",
    "with open('t1.pickle', 'wb') as handle:\n",
    "    pickle.dump(t1,handle)\n",
    "imp1 = {}\n",
    "imp2 = {}\n",
    "for key,value in t1.word_index.items():\n",
    "  imp1[value] = key\n",
    "  imp2[key] = value\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.dense = Dense(self.units,name = 'Enc_dense')\n",
    "\n",
    "    \n",
    "    def call(self,img):\n",
    "      '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "      '''\n",
    "      #enc_out = self.maxpool(tf.expand_dims(img,axis = 2))\n",
    "      enc_out = self.dense(img)\n",
    "      return enc_out\n",
    "\n",
    "\n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      self.batch_size  = batch_size\n",
    "\n",
    "      self.enc_h =tf.zeros((self.batch_size, self.units))\n",
    "\n",
    "      #self.enc_c = tf.zeros((self.batch_size, self.lstm_size))\n",
    "      return self.enc_h\n",
    "         \n",
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "  def __init__(self,att_units):\n",
    "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "    super().__init__()\n",
    "\n",
    "    self.att_units = att_units\n",
    "\n",
    "    self.w1 =  tf.keras.layers.Dense( self.att_units , name = 'w1')\n",
    "    self.w2 =  tf.keras.layers.Dense( self.att_units,name = 'w2')\n",
    "    self.v =  tf.keras.layers.Dense(1,name = 'v')\n",
    "\n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    self.decoder_hidden_state = decoder_hidden_state\n",
    "    self.encoder_output = encoder_output\n",
    "\n",
    "\n",
    "    self.decoder_hidden_state = tf.expand_dims(self.decoder_hidden_state,axis = 1)\n",
    "    score = self.v(tf.nn.tanh(\n",
    "              self.w1(self.decoder_hidden_state) + self.w2(self.encoder_output)))\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "    context_vector = attention_weights * self.encoder_output\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    return context_vector,attention_weights\n",
    "\n",
    "\n",
    "\n",
    "class OneStepDecoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units  ,att_units):\n",
    "      \n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "      super().__init__()\n",
    "      self.tar_vocab_size = tar_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units = dec_units\n",
    "      self.att_units = att_units\n",
    "      self.dec_emb = Embedding(tar_vocab_size,embedding_dim,trainable = True , name = 'dec_embb')\n",
    "      self.dec_lstm = GRU(self.dec_units, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n",
    "      self.dense   = Dense(self.tar_vocab_size, name = 'one_dec')\n",
    "      self.attention=Attention( self.att_units)\n",
    "      self.d1 = Dropout(0.3,name = 'd1')\n",
    "      self.d2 = Dropout(0.3,name = 'd2')\n",
    "      self.d3 = Dropout(0.3,name = 'd3')\n",
    "\n",
    "  @tf.function\n",
    "  def call(self,input_to_decoder, encoder_output, state_h):\n",
    "    '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    '''\n",
    "    self.input_to_decoder = input_to_decoder\n",
    "    self.encoder_output = encoder_output\n",
    "    self.state_h = state_h\n",
    "\n",
    "    #A\n",
    "    target_embedd           = self.dec_emb (self.input_to_decoder)     #(batch_size,1,embedingdim)\n",
    "    #B\n",
    "    target_embedd = self.d1(target_embedd)\n",
    "\n",
    "    context_vector,attention_weights=self.attention(self.state_h,self.encoder_output) #context vector shape = (batch_size,att_units)\n",
    "    #C\n",
    "    concated = tf.concat([  tf.expand_dims(context_vector, 1),target_embedd], -1)\n",
    "    concated = self.d2(concated)\n",
    "\n",
    "    #D\n",
    "    lstm_output, hs      = self.dec_lstm(concated, initial_state=self.state_h)\n",
    "\n",
    "    lstm_output = tf.reshape(lstm_output, (-1, lstm_output.shape[2]))\n",
    "    lstm_output = self.d3(lstm_output)\n",
    "    #E\n",
    "    op = self.dense(lstm_output)\n",
    "    #op = tf.squeeze(op,[1])\n",
    "    return op,hs,attention_weights,context_vector\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      super().__init__()\n",
    "      self.out_vocab_size = out_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units = dec_units\n",
    "      self.att_units = att_units\n",
    "      \n",
    "      self.onestep = OneStepDecoder(self.out_vocab_size,self.embedding_dim ,self.input_length,self.dec_units,self.att_units)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state):\n",
    "\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "\n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        # Return the tensor array\n",
    "\n",
    "        all_outputs = tf.TensorArray(tf.float32,size =input_to_decoder.shape[1],name = 'output_arrays' )\n",
    "        self.input_to_decoder = input_to_decoder\n",
    "        self.encoder_output = encoder_output\n",
    "        self.decoder_hidden_state = decoder_hidden_state\n",
    "\n",
    "        for timestep in tf.range(input_to_decoder.shape[1]):\n",
    "          op,hs,attention_weights,context_vector = self.onestep(self.input_to_decoder[:,timestep:timestep+1], self.encoder_output, self.decoder_hidden_state)\n",
    "          self.decoder_hidden_state = hs\n",
    "          all_outputs = all_outputs.write(timestep,op)\n",
    "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        return all_outputs\n",
    "class encoder_decoder(tf.keras.Model):\n",
    "  #def __init__(self,#params):\n",
    "    #Intialize objects from encoder decoder\n",
    "  def __init__(self,out_vocab_size , embedding_size_d, input_length_d,lstm_size_d,att_units,batch_size,units):\n",
    "\n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        super().__init__()\n",
    "\n",
    "        self.units = units\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size_d = embedding_size_d\n",
    "        self.lstm_size_d = lstm_size_d\n",
    "        self.input_length_d = input_length_d\n",
    "        self.batch_size = batch_size\n",
    "        self.att_units = att_units\n",
    "\n",
    "        self.encoder = Encoder(self.units)\n",
    "        print(\"OUT_VOCAB_SIZE = \",out_vocab_size, embedding_size_d,input_length_d,lstm_size_d,att_units)\n",
    "\n",
    "        self.decoder = Decoder(out_vocab_size , embedding_size_d, input_length_d,lstm_size_d,att_units )\n",
    "        #self.dense   = TimeDistributed(Dense(self.out_vocab_size, activation='softmax'))\n",
    "        self.dense   = Dense(self.out_vocab_size,name = 'enc_dec_dense')\n",
    "\n",
    "\n",
    "\n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    # return the decoder output\n",
    "    self.inputs,self.outputs = data[0], data[1]\n",
    "    print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
    "    self.encoder_h= self.encoder.initialize_states(self.batch_size)\n",
    "    self.encoder_output = self.encoder(self.inputs)\n",
    "    print(\"-\"*27)\n",
    "    print(\"ENCODER ==> OUTPUT SHAPE\",self.encoder_output.shape)\n",
    "    print(\"ENCODER ==> HIDDEN STATE SHAPE\",self.encoder_h.shape)\n",
    "    print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
    "    output= self.decoder(self.outputs,self.encoder_output,self.encoder_h)\n",
    "    print(\"-\"*27)\n",
    "    print(\"FINAL OUTPUT SHAPE\",output.shape)\n",
    "    print(\"=\"*50)\n",
    "    print(\"output = \", self.dense(output))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "\n",
    "  return tf.reduce_mean(loss_)\n",
    "  #out_vocab_size , embedding_size_d, input_length_d,lstm_size_d,att_units,batch_size)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose = 1,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8,mode = 'min',verbose = 1,\n",
    "                              patience=2, min_lr=0.0001)\n",
    "\n",
    "model_1 = encoder_decoder(vocab_size_imp,300,76,256,64,50,256)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model_1.compile(optimizer=optimizer,loss=loss_function, metrics = \"accuracy\")\n",
    "\n",
    "train_inp = np.vstack(X_train[:,4]).astype(np.float64)  # Use np.float64 for double-precision floats\n",
    "test_inp = np.vstack(X_test[:,4]).astype(np.float32)  # Use np.float32 for single-precision floats (if memory efficiency is a concern)\n",
    "\n",
    "model_1.fit([train_inp,dec_inp ],dec_op ,validation_data= ([test_inp, dec_inp_cv],dec_op_cv),batch_size= 50,epochs  = 1,callbacks=[reduce_lr,model_checkpoint_callback] , shuffle=True)\n",
    "\n",
    "\n",
    "now show with and example from the above data how and when classes are initilized and what they return what they do and show the output , when they do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6ee65-29d1-4785-8307-63e3650bbdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
